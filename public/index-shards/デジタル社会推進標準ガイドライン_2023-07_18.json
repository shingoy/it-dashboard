{"shard_id":"デジタル社会推進標準ガイドライン_2023-07_18","group":"デジタル社会推進標準ガイドライン_2023-07","chunk_count":50,"chunks":[{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c71","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"活かすこともできます （次節のFMEAの分 析例で、優先順位付けの事例を紹介しています） 。\n\npage 69 8. 安全設計とリスクマネジメン ト 8.6 FMEA （Failure Mode and Effects Analysis） 故障モード影響解析 （FMEA） は、想定されうる故障やエラー等の一覧を作成し、それぞれの影響度や発生確 率に基づいて優先的に対策すべき項目を特定する手法です。使用エラーが引き起こすトラブルを事前に抽出し、 リスクを定量的に把握する際に有効です。 8.6.1 FMEAの作業手順 作業プロセスの明確化 システムや業務の一連の手順 （分析の対象を細かく区切る） で具体的な操作や手順 （作業プロセス） を洗い出す。 想定されうるエラーの列挙 作業プロセスごとにエラーが起きうるもの （故障モード） を列挙する。 影響評価 エラーによって引き起こされる結果 （波及事故） を評価し、回復に要するコストや発生確率を基準として 「致 命度」 を算出する。表に示した例では、回復コストと発生確率をかけ合わせて致命度を評価しています。 観察による補強 （可能な場合） 実際","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":69,"page_to":71,"char_count":1170},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c72","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"HAZOP （HAZard and OPerability Studies ） FTAやFMEAと並びよく使われるリスク解析方法です。HAZOPでは 「ない」 「反した」 「よりも早く」 といっ た 「設計意図・通常の利用方法」 からのずれを 「ガイドワード」 として用意してブレインストーミング等を行い、 分析を行う手法です。プロセスを分析の対象とするノードに分解し、ノードごとに分析を行います。﻿ ●ノード1：ログイン認証 ●ノード2：申請フォーム入力 ●ノード3：添付書類アップロード ●ノード4：内容確認 ●ノード5：送信・完了 元々は化学プラントの安全設計のために開発された手法なので、ユーザビリティの解析に使うためには、ガ イドワード等を改良したものを使います。﻿ ガイドワード エラー 責任 発生事故 抜かす ステップを抜かす 使用者・使用状況 手続が完了できない 繰り返す フォーム でクリックを繰り返す 両方 情報が重複し て送信されて しまう 忘れる 提出を忘れる 使用者・使用状況 手続が完了できない 急いで 急いで作業する 使用者・使用状況 重要な情報を見落とす ゆっく り ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":71,"page_to":72,"char_count":1230},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c73","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"的評価 （Probabilistic﻿Risk﻿Assessment:﻿PRA） です。PRAは、 リ スク事象の発生確率およびそれに伴う影響を定量的に評価し、リスクに関する意思決定を合理的に支援するこ とを目的としたアプローチです。PRAは特に、原子力施設における安全評価の分野で長年活用されており、複 雑なシステムの構成要素がどのように相互作用してリスクに至るかを把握する上ではある程度有効です。 ただ、以下のような特徴を持つソフトウェア開発プロジェクトでは、PRAは導入に一定の制約がある手法で あり、本ガイドブックでは深く踏み込みません。 ●統計的・定量的な情報が十分に蓄積されていない ●対象システムが動的かつ複雑であり、因果関係が明確でない ●未知のリスクや設計初期段階での不確実性に対応したい ●人的要因やソフトウェアの設計ミス等定量化が困難な要素を扱いたい ●デザインプロセスへの柔軟な統合が求められる PRAは 「原因と結果のチェーン」 を重視しているため、 過去の事故データやイベントツリー分析、 フォールト ツリー分析を使ってリスクを定量的に評価していきます。このため、構成が変","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":72,"page_to":73,"char_count":1296},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c74","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"生確率を評価し、 リスクの低減策を導くことを目的とした評価活動のことです。 従来の確率論的リスク評価 （PRA ［8.8］ ） では、 人の行動を確率的に扱うことが前提であり、 複雑な認知判断や 環境要因の影響までは十分に捉えきれないという課題があります。HRAはこうした限界を補い、人的要因をよ り深く理解しながら、安全設計に反映させるための枠組みです。HRAはいくつかのアプローチに分けられます。 ●第1世代のアプローチ 主に作業手順に従った行動の逸脱確率を、経験的データに基づいて推定する手法です。代表的なものに、 THERP （Technique﻿for﻿Human﻿Error﻿Rate﻿Prediction） やSLIM （Success﻿Likelihood﻿Index﻿Method） があります。 ●第2世代のアプローチ 人間を意思決定主体としてとらえ、作業コンテキストや認知過程を重視するモデルです。心理学や認知 科学の知見を取り入れた手法として、 CREAM （Cognitive﻿Reliability﻿and﻿Error﻿Analysis﻿Method） やATHEANA ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":73,"page_to":74,"char_count":1285},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c75","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ト 8.10 HRAとFTAの併用による使用エラーの分析例 HRAは人的エラーの発生確率や背景要因を評価する手法であり、FTA （Fault﻿Tree﻿Analysis） はリスク要因の論 理的構造を視覚化する手法です。両者を組み合わせることで、リスクの定量評価と因果関係の構造化を同時に 行うことができます。以下に、病院における薬剤投与業務を例に、HRAとFTAの併用による分析の手順を示し ます。 8.10.1 使用エラーの分析と確率評価 （HRA） 病院の薬剤投与システムにおいて、 以下のような使用エラーが想定されるとします （※確率は例示です） 。これ らのエラータイプ （発生要因ベース） には、 ［6.3］ で紹介したラスムッセンのSRK （Skill-Rule-Knowledge） モデル や、J・リーズンのGEMS （Generic Error-Modelling System） を基盤として用います。 ●スリップ （誤選択） ：看護師が正しい薬剤を認識しているが、隣の薬剤を手に取る （確率: 0.1） （注記） 。 ●ラプス （忘却） ：看護師が指示通りの時間に薬を投与し忘","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":74,"page_to":75,"char_count":1258},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c76","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"造を持ち、他のシステムやサービスとの相互接続性が高まっていま す。例えば、複数のWebサービスが連携したり、新たな機能が継ぎ足されて運用されたりする中で、個々の設 計者が想定しなかった相互作用によって事故や障害が引き起こされるリスクが増加しています。 従来の安全工学 （Safety-I） は、 「事故の防止」 に焦点を当て、個別の故障や人的エラーを排除することで安全 性を確保しようとしてきました。しかし、ホルナゲルらが提唱するSafety-IIのパラダイム （Hollnagel,﻿2006） で は、 「うまくいくことの確保」 に重点を置き、システムの適応能力と回復力 （レジリエンス） を重視します。 背景には、現代的な情報システムが抱える 「複雑性」 と 「密結合性」 があります。特に以下のような状況では、 従来型の因果分析や故障前提のアプローチでは対応が困難であり、これまでに紹介してきた 「個別のエラーや 故障の原因と結果」 に注目するリスク分析手法では不十分です。 ●複数のコンポーネントや組織が関与し、全体像が見えにくいシステム ●ヒューマンファクターや組織的要因が影響するシステ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":75,"page_to":76,"char_count":1216},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c77","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"AMP/STPA STAMP/STPAは、 レブソンが提唱したシステム思考と制御理論に基づいた安全分析手法 （Leveson,﻿2012） です。 システムの構造や制御の失敗に着目し、ヒューマンファクター （人的要因） や組織要因も含めて全体的な安全性 を評価できることが特徴です。特に、 ソフトウェアの影響が大きい現代の複雑なシステムにおいて、 STPAは有 効な分析手段として注目されてきました。 9.1.1 STAMP/STPAのキーコンセプト STAMP/STPAは、 事故の発生を個別要素の故障ではなく、 システム全体における安全制約 （Safety﻿Constraints） の不備として捉える枠組みです。ここでいう 「システム」 とは、 情報システムそのものに限らず、 関係組織、 運 用者、 規則や社会的要請を含んだ全体構造を意味します。STAMPでは、 これらの構成要素が相互作用する構造 の中で、安全制約をどのように維持するかを分析対象とします。システム全体の構造を制御の視点からモデル 化する際には、主に階層的な安全制御構造を用いた整理を目指します。 これは、 政策決定層、 組","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":76,"page_to":77,"char_count":1114},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c78","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"STPAではそのような複雑な関係 性も柔軟にモデル化することができます。関係者間での柔軟な思考や創発を促すことを念頭に置きながら、シ ステムの特性に応じて制御構造の定義に取り組むことが求められます。\n\npage 76 9. システム思考に基づく 安全設計のアプローチ さてここまで 「コントローラー」 とは何かを具体的に説明してきませんでしたが、 以下の要件を満たしている ものがコントローラーです。 ●なんらかの制御アルゴリズムを持っている （STAMPの文脈では特に、安全のための制約、判断） ●他のコントローラー （システム） に影響を与えることができる （コントロールアクションの出力） ●システムの状態を観測することができる （フィードバックの受信） ●コントロール対象となるプロセスに対応したプロセスモデル （どんな状態にあるときになにができるのか、 状態変数とプロセスの遷移） を持つ STAMPを安全の設計や解析に応用するための手法がSTPAです。 「十分な情報かつ適切なタイミングで」 （適切 性及び適時性） 各コントローラーがコントロールアクションを行い、その結果がコントローラー","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":76,"page_to":77,"char_count":1175},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c79","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ョンが実行されたことが不適切 （例：誤入力） ●コントロールアクションが実行されなかったことが不適切 （例：必要な操作を行わない） ●実行のタイミングが早すぎる／遅すぎる ●順序の誤りや文脈誤認によって、誤った判断がなされる これらのUCAに注目することで、例えば 「誤入力」 「確認漏れ」 「判断の混乱」 等の使用エラーを、システムの 構造やフィードバックループとの関係で可視化することができます。\n\npage 77 9. システム思考に基づく 安全設計のアプローチ 9.1.4 システムの実際の挙動とプロセスモデルのずれを分析する STAMPでは、 事故の多くは 「意図的な違反」 よりも 「合理的に見えた行動が結果として不安全だった」 という 構造に起因すると考えます。これは、 コントローラーが保持するプロセスモデル （＝対象の理解や予測） が、 現実 のシステム挙動とずれていることで生じます。 STAMPにおけるプロセスモデルの不整合分析は、 認知工学におけるメンタルモデル研究と類似の課題を扱い ますが、理論的基盤は異なります。プロセスモデルは制御理論に基づく 「制御対象の内部表現」 ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":77,"page_to":78,"char_count":1277},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c80","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"慮に入れたデザイン及び開発を行うことができます。また、 本手法はセキュリティインシデントを防ぐための手法としても活用できます。 本セクションでは、基本プロセスとデザインプロセスへの導入のヒントを紹介します。本手法について詳し く知りたい方は、 IPAが発行しているガイドブックや民間の解説書を参考にしてください。IPA版ガイドブック には、日本の利用者向けに適応した手順、分析例等が網羅されています。\n\npage 78 9. システム思考に基づく 安全設計のアプローチ 9.2 STPAの基本プロセス ここからは、STAMPに基づいて事故やハザードの予防を目的とした安全解析手法であるSTPAの基本的なプ ロセスを見ていきます。主に以下のステップで構成されています。 ●分析目的の明確化と安全目標の設定 ［9.2.1］ ●コントロールストラクチャ （Control Structure） の可視化 ［9.2.2］ ●安全でないコントロールアクションを抽出する ［9.2.3］ ●安全でないコントロールアクションが引き起こされる要因やプロセスを特定する [9.2.4] ●安全制約を満たすための制御構造","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":78,"page_to":79,"char_count":1271},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c81","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"準 ●マニュアルや運用ルールの変化 ●緊急時対応の柔軟性 残念ながら （どんな手法においてもそうですが） 「なにが安全なのか」 「何を回避するべきなのか」 を定義しきる、 簡単で完全な手法はありません。本ガイドブックの前半でも示したように、ユーザビリティは使っているとき の文脈や環境、利用者の知識等によって影響を受けます （ハザードランプの示す意味が文脈によって変わる例を思い 出してください） 。また、ここでいう 「システム」 には、 ［9.1.1］ でも示したように、安全性を担保する組織や人 も 「システムの構成要素」 として含んでいます。組織文化やオペレーターの 「慣れ」 や経年変化等によっても安 全は脅かされうるのです。 例えば空港の航空管制を例に考えてみましょう。航空管制は、出域管制 （離陸） 、入域管制 （着陸） 、タワー管 制 （滑走路管理） といった複数の制御主体 （コントローラー） が協調して運用されています。出域管制は離陸機の安 全を、入域管制は到着機の安全を受け持つと （ここでは試しに） 定義するとします。このときに各管制が最も注\n\npage 79 9. システム思","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":79,"page_to":80,"char_count":1208},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c82","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ならない」 「常に○○を確認する必要がある」 といった形で、 具 体的かつ制御的に定義されるべきものです。安全制約を定めるには、こうした安全性に影響を与える要素や文 脈等の全体像を十分に洗い出し、関係者間で、どのような目標に向かって設計を行うのか合意していく必要が あります。 自動運転システムの安全目標の例を見てみましょう。自動運転車両では、以下のような包括的かつ現実的な 安全目標が考えられます。 ●交通状況に関係なく安全に運転を維持する ●人が乗り降りしているときにも、事故や挟まりが起きないよう制御する ●万一事故を起こした場合も、乗員・被害者・歩行者の安全を最優先する ●災害時・緊急事態下では、乗員及び周囲の人の安全を確保する動作に切り替わる これらの目標は、 「事故を起こさない」 ことだけでなく、 「事故やハザードが発生しても被害を最小限に抑える」 という視点から設定されるべきです （＝フェイルセーフやリカバリの観点を含む） 。また、 以下のようなハザードの 管理体制上の曖昧さを見逃さず分析することも重要です。 ●コントローラーの誰も責任を負っていないハザード ●複数のコントロー","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":80,"page_to":81,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c83","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"rolled Process） コントローラーの指示によって振る舞いが変化する対象。車両、システムUI、現場オペレーター等。 ●コントロールアクション （Control Action） コントローラーが出す命令・操作指示 （例： 「ドアを閉める」 「エアバッグ展開」 等） ●フィードバック （Feedback） コントロール対象プロセスからコントローラーに返る情報 （例： 「ドアが閉じた」 「エンジン異常あり」 等） ●コントロールアルゴリズム （Control Algorithm） プロセスモデルと入力に基づいて、どのアクションをいつ実行するか判断する内部ロジック コン トローラー 指示（コン トロールアクション） フィードバック コン トロール対象となる システムのふるまい（被コン トロールプロセス） コン トロール アルゴリズム プロセスモデル 出力 入力 図9.2 コン ト ローラーと コン ト ロール対象プロセスの相互作用を示す基本的なモデル。 また、各コントローラーは内部に （コントロール対象プロセスに対する） プロセスモデル （Process﻿Model） を持ち、 プロ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":81,"page_to":82,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c84","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ウェア、監視者 ●コントロール対象プロセス：車両のブレーキ、アクセル、ステアリング ●フィードバック：センサーからのデータ （車速、車間距離、現在位置等） 。 自動運転ソフ トウェア センサー群 意思決定者 アクチュエータ制御システム 運転者（利用者） 速度制御 統合制御 ブレーキ 速度センサー 測位センサー 車載カメラ アクセル 車両の物理的な動作 ステアリング 経路計画 障害物認識 介入（コン トロールアクション） 制約条件 緊急停止・回避行動要求 目標軌道 加減速要求 目標速度 自動車の状態をフィードバック 制動・加速・操舵指示 天候や路面状況等の外部要因 制御 自動車・周辺環境の状態を フィードバック 制御状態をフィードバック 計測 コン トロール対象プロセス 図9.3 自動運転を例と し た制御構造図 （CS図） の例。 制御構造図の作成は、単なる図解作業ではなく、関係者間で 「安全性とは何か」 「制御はどう行われているか」 を共有 ・ 可視化する重要なコミュニケーションツールにもなります。この図に基づいて、 次のステップでは 「非 安全なコントロールアクション （UCA） ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":82,"page_to":83,"char_count":1192},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c85","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"：停止線を越えた後にブレーキがかかる、信号よりも早く発進する。 ●④ アクションが必要な時間よりも長く／短く続く 例：機首を下げ続けたまま戻らない、加熱処理が途中で停止する。 このような形式で分類することで、操作の不在・過剰・不適切なタイミング・時間といった観点でリスクを網 羅的に洗い出すことができます。例えば、自動運転車のコントロールアクションを想定すると、次のような組 み合わせが考えられます。 コントロールアクション （CA） 非安全な実行例 （UCA） アクセルを踏む 危険な状況でアクセルを踏んでしまう （②） ブレーキをかける 必要なときにブレーキが作動しない （①） 方向を変更する 変更のタイミングが遅れ、衝突する （③） アラートを表示する 表示が早すぎ／遅すぎ／表示されない （①〜③） 非安全なコントロールアクションの洗い出しには、HAZOP ［8.7］ で紹介したガイドワードを応用することで、 網羅的な検討がしやすくなります。例として以下のようなキーワードが使えます。 ●Not executed （実行されない） ●Too early / Too late （早すぎる／","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":83,"page_to":84,"char_count":1202},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c86","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"因 （Hazard Causal Factor: HCF） 、そしてそれがどのような過程で損害につながるのか （Hazard Scenario: HS） を特定し、安全 制約を強化するための設計改善へとつなげていきます。 HCFは、UCAが発生してしまう背景にある構造的、認知的、プロセス的な原因要因、組織運用等、幅広い範 囲で発生する制御上のギャップを意味します。例えば次のような事象が該当します。 ●コントローラーのプロセスモデルが実状と食い違っている ●入力情報が誤っている、または不足している ●コントロールアルゴリズムが適切でない ●フィードバックが遅延／欠落している このような原因が、コントロールアクションの誤りや判断ミスを引き起こすことで、結果としてハザードを誘 発します。注意すべきは、人間の行動は静的なアルゴリズムではなく、状況やフィードバックに応じて動的に 変化するという点です。システムと対話するオペレーターは、システムの反応を見て判断を変えたり、ルール を補完的に解釈することがあります。ここで、オペレーターに正常性バイアスが働いたり、システムイメージ を適切に認知できてい","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":84,"page_to":85,"char_count":1292},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c87","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"スモデル 通信エラーで自動運転がコントロールアクション を送信できない フィードバックの欠落／制御経路の脆弱性 制御の遅延により危険回避が間に合わない リアルタイ ム処理不足、制御設計の非現実性\n\npage 84 9. システム思考に基づく 安全設計のアプローチ HCFを元に特定されたリスクを軽減させるため、設計を見直します。 ●安全制約の再評価・強化 冗長化、フェイルセーフの導入等を検討します。 例：センサーの二重化、予備系の切り替え設計 ●制御構造・フィードバック経路等のコントロールプロセスの改良 情報伝達の信頼性向上、監視強化等を検討します。 例：ソフトウェアの状態監視とリカバリプロセスの追加 ●人間の動的な変化に配慮した設計 メンタルモデルの明示等のUXデザイン、UIデザインの再検討を行います。 例：フィードバック情報の可視化、リハーサル機能の導入 ●組織・責任の可視化とルール整備 責任の空白や競合をなくす構造を設計に埋め込みます。 例：複数部署が関わる場合の安全チェックポイントの明示化 HCFは 「なぜUCAが起きたのか」 を構造的に説明する鍵であり、 HSは 「それがどう損","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":84,"page_to":86,"char_count":1249},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c88","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ドを定義する 例：患者への誤投薬、サーバーダウン、列車の遅延﻿等。分析対象システムの境界と発生した事故の詳細 を明確化する。 ●安全制約を明らかにする 事故防止のために本来維持されるべきだった制約を特定する。 ●安全制御構造を可視化・文書化する 制約がどう破られたか、関与したコントローラーの制御構造を明らかにする。 人的／システム的コントローラー、コントロールアクション、フィードバックの有無など。 ●各コントローラーのプロセスモデルと認知状況を分析し、安全制約違反 （欠陥） を特定する 人がコントローラーであれば 「合理的に思えた判断、その要因は何だったか」 、 「情報に欠落や誤認はな かったか」 。 ●組織的・設計的な背景要因 （HCF） を抽出する 物理プロセス、技術・運用、組織・管理、政府・規制の各レベルで要因を特定する。 ●改善策・再発防止策を導出する 大枠の手順はSTPAで紹介したものと同じなので、ここでは詳説しませんが、ユーザビリティ確保の観点から 重要なポイントを紹介します。 9.3.2 CASTの観点をユーザビリティ テストで援用する CASTの観点は、ユーザビリティテ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":86,"page_to":87,"char_count":1262},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c89","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ィードバックループは途切れていなかったか？ （コミュニケーションミスマッチ） ●組織として、そのコントロールアクションをサポートできていたか？ ●手順・権限・責任は適切に分担されていたか？ STAMPに基づく安全設計では、 STPAによる事前の予防的分析と、 CASTによる事後の因果構造分析を組み合 わせることで、 設計と運用の間に連続性を持たせ、 より強固な安全文化の構築を目指すことができます。CAST で明らかになった以下のような事象は、STPAのフィードバックとして再利用することもできます。 ●安全制約の不備：新しい制約の追加 ●認知・プロセスモデルの誤り：人的要因をより深く反映したモデル化 ●コントローラー間の責任のあいまいさ：制御構造の再設計 STPAやCASTで明らかになった非安全な制御構造や要因を一度限りの対応で終わらせず、 システムや組織そ のものが学習し、より適応的な安全性を構築していくためには、 「ダブルループ学習」 の考え方が重要になるこ とも覚えておきましょう。これは、事故やインシデントの発生時に、単に行動 （例：手順やUI） を修正するだけ ではなく、その行動","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":87,"page_to":88,"char_count":1292},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c90","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"うな要素を明確に定義しておく必要があります。 ●提供しようとしている製品・サービスの特性とリスク特性の把握 （パフォーマンス観察・評価） ●安全な状態とはなにかを組織内で定義し、共有する ●安全目標の達成に向けて、どのような情報を、どのように活用して判断を下すかという意思決定の流れ （合意形成のための組織的プロトコル） を整備する ●人的・財政的リソースを確保する 図10.1 RIDMのプロセス。 安全目標に対し て のパフ ォ ーマ ン スを観測 ・ 評価し、 把握された リ スク特性に基づいた意思決定、 実行のサイ ク ルを繰り 返す 。 近年の安全工学においては、 単に 「事故やインシデントを防止する」 ことを目標とするのではなく、 発生を前 提とした 「安全のコントロール」 （Safety-II） へと発想がシフトしています。つまり、 失敗をゼロにすることより も、失敗が起きても被害を最小限に抑えるよう、システムの構造を設計することが重要とされています。第９ 章の冒頭でも述べたように、使用エラーやハザードを排除するのではなく、 「うまく対処できる」 適応能力と回 復力 （レジリ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":88,"page_to":89,"char_count":1237},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c91","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ず、 合理的な判断の中心要素として位 置づけるプロセスです。RIDMの特徴は、 単なる 「安全第一」 ではなく、 「目的を達成しながらリスクをどのよう に受容・制御するか」 を評価し、複数の選択肢の中から、最も妥当で実行可能な解を選ぶ点にあります。RIDM は以下のようなステップで実施されます。このプロセスは、安全工学に限らず、UI設計や運用業務の変更、サ プライチェーンリスク等にも応用可能です。 ●課題の特定とスコープ設定 ●関連するリスク評価情報の収集 ●設計・運用案 （選択肢） の策定 ●選択肢ごとのリスク比較と評価 ●価値判断と合意形成に基づく意思決定 ●決定根拠の文書化とフィードバックの活用 10.2 リスク評価情報の可視化と説明責任 リスク情報に基づいて意思決定を行うにあたり、評価内容が誰にとっても理解できる形で表現されているか、 そしてその判断の根拠が将来にわたって追跡可能かどうかは極めて重要です。いかに定量的なリスク評価がな されていても、それが一部の専門家だけに理解されるような形では、意思決定の正当性を社会的に説明するこ とは困難です。リスク情報の 「可視化」 と 「","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":89,"page_to":90,"char_count":1267},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c92","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"れます。 ●評価時点での仮定・前提条件の記録 ●使用したデータ・手法・モデルの明記 ●判断における選択肢と理由づけの文書化 ●意思決定に関与した関係者と合意形成の過程 このようにして、意思決定の背後にある思考プロセスを外部化・文書化することで、後から検証可能な状態を 保ちます。これは、単に 「安全である」 と主張するのではなく、 「どのように安全と判断したか」 を透明にする ために大切な観点です。記録管理については、 「DS-680.2﻿ウェブコンテンツガイドライン」 ［16﻿公開情報の品 質確保］ 及び ［18﻿記録管理］ も援用できるものですから、参考してください。\n\npage 90 10. リスク情報を活用した意思決定 10.3 安全文化と学習サイクルへの統合 リスクに基づいた意思決定を一過性の対応で終わらせないためには、組織全体で安全に対する共通理解と継 続的な学習の仕組み＝ 「安全文化」 を醸成する必要があります。ここでいう安全文化とは、 「安全は現場任せで はなく、組織全体の価値判断として根づくべきものである」 という認識に立ち、日常的な意思決定にリスク評 価を組み込む態度","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":90,"page_to":91,"char_count":1186},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c93","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"善提案を共有しても非難されない」 組織的な土壌＝心理的安全性 （Psychological﻿ Safety） を確保することです。 心理的安全性とは、 「この場で自分の考えを発言しても拒絶されたり評価を下げられたりしない」 と信じられ る状態のことであり、効果的なチームの最重要要因として繰り返し示されています。この心理的安全の醸成を 図るには、組織・チーム内での関係性の質を高めなければなりません。ダニエル・キムが提唱した 「成功循環 モデル （Core﻿Theory﻿of﻿Success） 」 は、組織の成果を 「結果」 から変えようとするのではなく、 「関係の質」 から見 直すことが、持続的な成果につながると説くものです。 要素 安全文化における意味 関係の質 上下・部署間を問わず、誰もが安全に発言・共有できる関係性 （心理的安全性） 思考の質 「この行動の背景には何があるか？ 」という構造的・非懲罰的な視点で考える 態度 行動の質 使用エラーやインシデントをオー プンに報告・記録・改善提案する行動の実践 結果の質 リスクの早期発見、安全設計の改善、組織とし ての信頼性の向上\n\npa","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":91,"page_to":92,"char_count":1269},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c94","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ぜそうしたのか？」 ではなく 「その時どう 見えたか？」 等） 。問いには、 クローズドな質問 （ 「はい/いいえ」 で答えられるもの） とオープンな質問 （具体的な列挙 や叙述が求められる質問） 、具体的な質問と抽象的な質問等をシーンに応じて使い分けると良いでしょう。 行動の質を変える制度 報告した人を責めず、 報告そのものを評価する仕組みの制度化。潜在的なリスクの 「見える化」 を推奨します。 なお、 行動の質を変えるには、 多様な立場の声を汲み取るフィードバック構造を作り、 各ステークホルダーがそ れぞれの認識・判断・行動に別々のプロトコルを持っていると十分に自覚することが重要なポイントです。横 断的な議論の場 （シナリオワークショップ等） を設けること等も有効でしょう。 結果の質を活かす循環 報告から得た教訓をUIや業務マニュアルに反映し、定期的に 「変更理由」 を周知する。社内WikiやLT （ライ トニングトーク） の実施等も有効です。 全体の振り返り 安全文化の維持・醸成のプロセスの循環が組織内でどのように行われたか、振り返りの機会を設けることも 大切です。心理的安全が損","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":92,"page_to":93,"char_count":1262},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c95","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"熟度等のスケール （尺度） を用いても良いでしょう。 10.4 合意形成 現代のシステムでは、複雑なルールと評価基準、技術仕様、ガイドラインが錯綜し、設計・開発・運用に関 わる多様なステークホルダーが共通理解を持つこと自体が難しくなっています。さらに 「機能改修単位で発注 が行われ、実装する受託事業者が異なる」 「複数のプロジェクトにまたがって設計・運用される」 情報システム も多くなっています。このため、横断的かつ整合性のある監査基準、言い換えれば組織内外での合意形成のプ ロセスの設計が求められています。 情報システムの品質評価の透明性や公平性が欠けると、 現場では 「規制への一時対応」 に終始してしまい、 本 質的なユーザビリティや安全性が置き去りになるリスクがあります。というのも、例えば成果物の品質確認を 行う人による対応や判断の差がある、あるいは評価基準が透明性を欠くものになっている場合、対応コストが 見通せず大きな負担になってしまいます （プロジェクトが 「炎上」 しているときは特にそうです） 。対応を迫られる事 業者側も規制への目先の対応を優先してしまい、真にユーザビリティ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":93,"page_to":94,"char_count":1261},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c96","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"共通の目標を共有できている状態をすぐに作れることは、情報システムの品質を継続的に向 上させるための土台になり、開発の失敗やインシデントのリスク低減につながります。 予見性 評価対象者 （事業者・開発者） が、必要な資源や対応策を事前に把握可能であるか。監査主体によって評価に 大きな違いがあると規制への目先の対応が横行するようになり、本来は中長期的に取り組むべき課題に取り組 めなくなってしまいます。開発の目標設定や設計の基準を定め、適切な開発プロセスを整備できるよう、品質 の基準を明確化することは、開発プロセスや工数の見通しを事業者や調達担当者が明確にする材料になります。 適時性 問題のある箇所を早期に特定し、修正できるプロセスが整備されているか。問題が発覚しても、修正するの に来年度まで待たなければならない状態では、情報システムを信頼して利用することができません。課題は発 見されるだけではなく、それが必要なタイミングで是正される必要があります。 公平性 「現実の利用状況における実際のパフォーマンス」 に焦点をあてているか。監査がチェックリスト偏重になる と規制が複雑かつ膨大になったり、","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":94,"page_to":95,"char_count":1292},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c97","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"非懲罰的かつ構造的な監査の文化を醸成する うえでも有用です。 10.4.1 安全に関する合意形成のためにやるべきこと 国民生活や企業活動に大きな影響を与えうる多くの行政サービスには複数の行政機関や業界団体、企業、専 門家、メディア等が関与しており、ステークホルダーの関係性も複雑です。これまで繰り返し述べてきたよう に、 「法令に従って設計されたから安心」 といった考え方はすでに限界を迎えています。むしろ、リスクが潜在 することを前提に、それらがどのように検出・制御・再設計されているかを、社会に対して説明し、共に評価 する枠組みが求められています。 このため、専門知識を持たない行政の担当者や、様々なステークホルダーが容易に取り扱える評価モデルを 共通言語として持ち、プロジェクト全体がチェックされるプロセスが正常に機能することで、社会的信頼が醸 成されるよう努めることが重要になってきます。 ●システムにどのようなハザードが潜在しうるかが構造的に可視化されていること ●想定される使用エラーや設計バイアスについて具体的に説明可能であること ●監査者・事業者・利用者のあいだで、評価基準とプロセス","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":95,"page_to":95,"char_count":1266},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c98","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"化 使用エラーや不確実性による影響 （損失） の可能性と、それに対する対策コストのバランスを確認・文書化し、 組織的に合意すること。このプロセスには、ヒヤリハットの蓄積やSTPAによる潜在的リスクの構造的把握が 含まれる。幅広い関係者からリスクに関する視点が提供され、 フレーミングの罠 （問題の枠組みフレームの設定の 仕方によって、判断や認識が偏ってしまう認知バイアス） に陥らないようにすること。\n\npage 95 10. リスク情報を活用した意思決定 パフォーマンスベースの評価 実使用状況に即した検証 （例：シナリオベース評価、クリック数、エラー率、達成時間） 。評価者間のばらつきを 最小化するためのプロトコル(手続き・手順)が整備され、計測できるようになっていること。検証者間での教 育・研修が行われ、定期的に指標や、環境の変化等を反映した活動が行われているか確認できること。システ ムのパフォーマンスに関する評価は、 「設計文書」 だけでなく、 「ユーザビリティテストの記録」 「インシデント ログ」 「UIプロトタイプ」 「A/Bテストの記録」 「コールセンターへの問合せ」 等の現物","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":95,"page_to":96,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c99","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"はできないことが出てきます。例えば以下のような問題です。 ●安全の基準を定義するのに、十分な情報がまだP J内にない ●リスク・ハザードの定義に、他のプロジェクトのリスク情報が必要である ●ある取組の優先順位が、プロジェクト単体で決められない （組織的決断が必要である） ●誰に、どのようなコミュニケーションをどのタイミングで取るべきかが定まらない ●複数のステークホルダーが安全確保において重要な役割を担っている こうした課題を乗り越えていくには、普段からプロセスの標準化や、十分に予見可能な対策の実施に向けた 情報・基準の管理が欠かせませんし、適切な記録管理が行われること、適切にスケジューリングされること等 も大切です。開発者・P JMO・利用者代表等多様なステークホルダーと随時コンテキストの共有が行われ、合 意形成のプロセスが段階的に踏まれていかないと、全員にとって負担が大きすぎることになるからです。 しかし、異なる階層・組織間でのコミュニケーションコストを低減させ、潜在リスクを早期に洗い出すため には ［10.3.1 安全文化のための制度的支援］ で示したような組織的な基盤が欠かせま","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":96,"page_to":97,"char_count":1259},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c100","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"が対話を通じて学び続けることが、事故の未然防止 だけでなく、信頼されるサービス設計に不可欠であることを強調しています。 従来、ユーザビリティと安全性やセキュリティ、プライバシーといった観点はしばしば別々に扱われがちで したが、本書を通じて、各要素は本質的に密接に結びついており、 「人が安心して使えること」 こそが、 「シス テム全体の信頼性を支える基盤」 であることをご理解いただけたかと思います。 現代の情報システムは、かつてないほど多くの人と技術が複雑に絡み合い、設計や運用の判断が難しくなっ ています。その中で私たちは、 「エラーが起きないように人を管理する」 という旧来型の発想から、 「エラーが 起きることを前提に、どう安全に制御するか」 というレジリエンス （回復力） を軸とした発想へと転換する必要 に迫られています。本ガイドブックが、そうした思考と実践の橋渡しを担い、より多くの機器・サービスが人 にとって使いやすく、安全で、信頼できるものとなる一助になれば幸いです。\n\npage 97 11. 付録 11 付録 11.1 リンク集 ユーザビリティに関するツールや情報は、多くがイン","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":97,"page_to":99,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c101","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"理推進機構\n\npage 98 11. 付録 11.2 参考文献 1. The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research. 1979. The Belmont Report: Ethical Principles and Guidelines for the Protection of Human Subjects of Research. U.S. Department of Health and Human Services. https://www.hhs.gov/ohrp/ regulations-and-policy/belmont-report/index.html 2. Amartya Sen. 1979. Equality of what? In The Tanner Lecture on Human Values, delivered at Stanford University (May 22, 1979). Stanfo","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":98,"page_to":99,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c102","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"er） https://ddc.dk/vaerktoejer/toolkit-the-digital- ethics-compass/ 7. 平沢 尚毅・福住 伸一 編／著 （2023） ． 『顧客経験を指向するインタラクション――自律システムの社会 実装に向けた人間工学国際標準』 ．日本経済評論社． 8. 福住 伸一・平沢 尚毅 （2024） ． 『詳説 ユーザビリティのための産業共通様式 CIF: Common Industry Format for usability』 ．近代科学社Digital． 9. Jakob Nielsen and Thomas K. Landauer. 1993. A mathematical model of the finding of usability problems. In Proceedings of the INTERACT '93 and CHI '93 Conference on Human Factors in Computing Systems (CHI '93). Association for Computing Machi","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":99,"page_to":99,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c103","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"mory processes in perception and cognition. In The Structure of Human Memory, C.N. Cofer (Ed.). W.H. Freeman, 114–132. 13. David E. Rumelhart and Andrew Ortony. 1977. The representation of knowledge in memory. In Schooling and the Acquisition of Knowledge, R.C. Anderson, R.J. Spiro, and W.E. Montague (Eds.). Lawrence Erlbaum Associates, 99–135. 14. Donald A. Norman. 1981. Categorization of action slips. Psychological Review 88, 1 (January 1981), 1–15. 15. James Reason. 1987. Generic error-modell","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":99,"page_to":99,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c104","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"le. In Resilience Engineering: Concepts and Precepts, E. Hollnagel, D.D. Woods, and N. Leveson (Eds.). Ashgate Publishing, 9–17. 20. Nancy G. Leveson. 2012. Engineering a Safer World: Systems Thinking Applied to Safety. MIT Press. 兼本茂・福島祐子監訳 （2022） ． 『システム理論による安全工学——想定外に気づくための思考法 STAMP』 ．共立出版．\n\npage 99 索引 あ行 アクセシビリティ ⸺ファー ストの原則… ……………………………………… 21 ⸺ファー ストの原則の説明… ……………………………… 22 ⸺の説明… ………………………………………………… 22 JIS X 8341シリー ズと⸺… ………………………………… 23 ⸺の環境整備・合理的配慮とし ての代替手段…………… … ……………… … …………………… … ……………","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":99,"page_to":100,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c105","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"… ………………………………………………… … ………………………………………………… 71 活性化消失エラー ⸺の説明 56 完了後エラー ⸺の説明 57 記述類似性エラー ⸺の説明 56 コミッションエラー ⸺の説明 54 さ行 自己記述性 ⸺の説明… ………………………………………………… … ………………………………………………… … ……………………………………… ……………………………………………… 26 システムイメージ ⸺の説明 17 人間中心の原則と⸺ 36 使用エラーと⸺ 53 シングルループ学習 ⸺の説明… ………………………………………………… … …………………………………………… … ……………………………………… … …………………………………………… … ……………………………………………… … …………………………………………… … ……………………………………………… … …………………… … ………………… ………………… 90 使用エラー ⸺の概要説明 12 ⸺への耐性の確保 30 ⸺の詳細説明 52 代表的な⸺ 54 意図しない⸺ 54 意図的","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":100,"page_to":100,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c106","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"……………………………… … …………… … ………………………………………………… …………………… … ………………………………………………… … ………………………… … ………………………………………………… 56 スリップ ⸺の説明 55 フォールトツリー分析 （FTA） を用いた⸺の評価 67 人間信頼性アセスメントを用いた⸺の評価 72 成功循環モデル ⸺の説明 90 た行 タイミングエラー ⸺の説明 54 対話の原則 ユーザビリティデザインの原則と⸺の関係 21 ⸺の説明 24 ダークパターン ディセプティブパター ンを見よ ダブルループ学習 ⸺の説明 90 多様性 多様性 リプレゼンテーションを見よ タンパープルーフ ⸺の説明 65\n\npage 100 索引 ディセプティブパターン ⸺とデザイン倫理… ……………………………………… … ………………………………………………… … ………………………………………………… … ………………………………………………… … ………………………………………………… 19 ⸺の説明 20 デザインモデル ⸺の説明 17 データ駆","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":100,"page_to":101,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c107","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"… ………………………………… 16 ⸺の説明 18 使用エラーと⸺の関係 30 情報提示の原則と⸺の関係 32 エラーチェー ン （事象連鎖） と⸺の関係 57 インシデント発生時の原因調査と⸺の関係 58 ハザード 使用エラーと⸺の関係 52 エラーチェーンにおける⸺の説明 57 ⸺の説明 63 STPAを用いた⸺の定義 76 STPAで特に注意すべき⸺………………………………… … ……………………………………… … ………………………………………… … …………………………………… … ……………………………………………… 77 ⸺の原因要因 （HSF） 81 ⸺シナリオ （HS） 82 ⸺シナリオ （HS） の例 82 ⸺の可視化 87 ヒューリスティック評価 ユーザビリティテスト （観察型） と⸺を組み合わせる… …… 43 ⸺の説明… ………………………………………………… … ……………………… ………………………… … ………………………………………………… …………………………………… …… … ………………………………………………… ………………………… …………","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":101,"page_to":101,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c108","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"リスク評価情報の可視化と⸺……………………………… … ………………………… … ………………………………………………… … ………………………… … ………………………………………………… … ……………………………………… … ………………………………………………… …………… ……………………………… … ………………………………………………… 87 フールプルーフ エラーチェー ン （事象連鎖） と⸺ 57 ⸺の説明 65 フェイルセーフ エラーチェー ン （事象連鎖） と⸺ 57 ⸺の説明 65 フールプルー フと⸺ 67 ま行 ミステイク ⸺の説明 55 フォールトツリー分析 （FTA） を用いた評価と⸺ 67 人間信頼性アセスメントと⸺ 73 メンタルモデル ⸺の説明 17 人間中心の原則と⸺… ……………………………………… ……………………………………………… ……………………………………………… … ………………………………………………… 36 使いやすさと⸺ 40 使用エラーと⸺ 53 モードエラー ⸺の説明 56\n\npage 101 索引 や行 ユーザーエクスペ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":101,"page_to":102,"char_count":1199},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c109","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"IF） 41 ⸺の評価手法 43 ⸺テスト 43 エキスパートレビューと⸺テスト 44 多様性 （リプレゼンテーション） の確保と⸺ 45 評価を実施するタイミングと⸺… ………………………… … ………………………… ……………………… … …………………… ………………………………………………… … ………………………………… ……………………………… … ……………………………………… ……………………… … ………………………………………… … …………………………………………… … ………………… … ………………………… …………………………………… 47 システムリプレー スと⸺テスト 47 新機能・新サービス開発と⸺テスト 48 安全設計とリスクマネジメントと⸺ 63 ⸺上のリスク 63 リスクアセスメントと⸺ 63 HAZOPを⸺の解析で用いる 69 安全目標の設定と⸺ 78 ハザードの原因要因の分析と⸺設計 84 CASTと⸺テスト 85 ⸺の合意形成 92 プロジェクトにおける⸺の説明責任 94 ⸺に関する横断的な意思決定 95 ユースエラー ユー スエラー 使用","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":102,"page_to":102,"char_count":1199},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c110","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"……………… … ………………………………………………… …………………………………… … ………………… … ………………………………………………… … ……………………………………… … ………………………………………………… … ……………………………………… … …………… … …………………………………… 55 人間信頼性アセスメントの実施例における⸺ 73 H HAZOP JIS Q 32012:2022における⸺ 61 ⸺の説明 70 確率論的リスク評価と⸺ 71 ⸺のガイドワードをSTPAで応用する 83 J JIS X 8341シリーズ ⸺の説明 23 R RIAS （Robotics, Intelligent and Autonomous System） 人間中心の原則と⸺ 36 RIDM （Risk-Informed Decision Making） ⸺の説明 87 ⸺の基本プロセス 88 安全文化の醸成のためのチェック項目と⸺ 92 ⸺と組織の合意形成 93\n\npage 102 11. 付録 page 102 索引 プロジェクト内での⸺の活用… ……………………","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":102,"page_to":103,"char_count":763},{"chunk_id":"fd5f7c4a4a9e8d973a68e5ced90ae4a5_c0","doc_id":"fd5f7c4a4a9e8d973a68e5ced90ae4a5","text":"デジタル社会推進実践ガイドブック DS-500 行政手続等における トラストおよびデジタルアイデンティティ に関するガイドライン群 2025 年（令和7 年）9 月30 日 デジタル庁 〔ドキュメントの位置付け〕 Informative：参考とするドキュメント 〔キーワード〕 トラスト、デジタルアイデンティティ、プライバシー、本人確認、身元確 認、当人認証 〔概要〕 国の行政機関が行政手続等において扱うトラストやデジタルアイデンティ ティに関する枠組み、対策基準、リスクの評価手順、本人確認、管理手法、 具体的な活用方法等を示した標準ガイドライン群の体系を表す文書。\n\ni 改定履歴 改定年月日 改定箇所 改定内容 2025 年9 月30 日 全般 ・第2 版改訂 ・トラスト関連ガイドライン群に関する文書体系の見直しに伴い DS-500 はガイドライン群の文書体系を管理するものと整理し、全 面改定。 ※初版の内容は、最新の状況等を踏まえて内容を大幅に刷新する とともに、文書番号をDS-511（DS-511-1）に変更。 2019 年2 月25 日 初版作成 ・初版決定\n\n2 １ トラストお","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"本文（PDF／284B）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/0bb1ca1b/20250930_resources_standard_guideline_trustidentityoverview_01.pdf","page_from":1,"page_to":3,"char_count":1229},{"chunk_id":"fd5f7c4a4a9e8d973a68e5ced90ae4a5_c1","doc_id":"fd5f7c4a4a9e8d973a68e5ced90ae4a5","text":"定が断続的に行われることが想定される。このため、 本文書を参照する際の参照元を明らかにすることを目的として、各文書の文書 番号には枝番を付すこととする。なお、初版時に限り枝番を不要とし、改版時 に初版に”-1”を、第２版に”-2”をそれぞれ付与することとする。 例： ⚫ DS-500-1 2019 年度版「DS-500 行政手続きのオンライン化における本人確 認の手法に関するガイドライン」を指す。 ⚫ DS-500-2 本文書(第二版”-2”)\n\n3 ⚫ DS-511「行政手続等での本人確認におけるデジタルアイデンティティの取 扱いに関するガイドライン」(DS-500-1 の改訂版。次期改版時はDS-511-1 となる) このため、DS-500 シリーズのガイドライン群を他の行政文書等で引用する場 合、枝番が付されたものは当該版を、枝番が付されないものは当該文書の最新 版を、引用しているものとすることを基本とする。 １．４ 文書の改訂および適用について 本ガイドライン及び本ガイドラインが規定する文書群の施行と同時に、2019 年度版「DS-500 行政手続きのオンライン化における本人確","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"本文（PDF／284B）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/0bb1ca1b/20250930_resources_standard_guideline_trustidentityoverview_01.pdf","page_from":3,"page_to":5,"char_count":1200},{"chunk_id":"fd5f7c4a4a9e8d973a68e5ced90ae4a5_c2","doc_id":"fd5f7c4a4a9e8d973a68e5ced90ae4a5","text":"回 2024/1/30 ・論点協議：本人確認ガイドライン改 定方針（案）について 令和５年度 第５回 2024/2/27 ・令和5 年度中間とりまとめ（案）につ いて ・追加の論点協議 令和６年度 第１回 2024/9/17 ・開催要綱説明 ・ガイドライン改定に向けた論点協議 令和６年度 第２回 2024/11/5 ・ガイドライン改定に向けた論点協議 令和６年度 第３回 2024/12/5 ・ガイドライン改定案の妥当性に関す る論点協議 令和６年度 第４回 2025/1/16 ・ガイドライン改定案の妥当性に関す る論点協議 令和６年度 第５回 2025/3/4 ・令和6 年度とりまとめ及び本人確認ガ イドライン改定案に関する意見交換\n\n5 １．２ 関係者 １．２．１ 有識者会議構成員（記載はあいうえお順。所属および役職は令和 6 年度有識者会議（第１回）時点のもの） 名前 所属及び役職 勝原 達也 アマゾン ウェブ サービス ジャパン合同会社 Specialist Solutions Architect, Security 後藤 聡 TOPPAN エッジ株式会社 事業推進統括本部 DX","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"本文（PDF／284B）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/0bb1ca1b/20250930_resources_standard_guideline_trustidentityoverview_01.pdf","page_from":5,"page_to":6,"char_count":1093},{"chunk_id":"fd5f7c4a4a9e8d973a68e5ced90ae4a5_c3","doc_id":"fd5f7c4a4a9e8d973a68e5ced90ae4a5","text":"トラスト政策班 千葉 亮輔（令和6 年 6 月時） 、當波 孝明(令和7 年7 月時)、松本 紗代子 ・アビームコンサルティング株式会社（委託事業受託事業者） ・宮部 麻里子、森 大輔","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"本文（PDF／284B）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/0bb1ca1b/20250930_resources_standard_guideline_trustidentityoverview_01.pdf","page_from":6,"page_to":6,"char_count":92},{"chunk_id":"8924e19b781c18e87de87f1d7774afd4_c0","doc_id":"8924e19b781c18e87de87f1d7774afd4","text":"デジタル社会推進実践ガイドブックDS-203 政府情報システムにおけるサイバーセキュリティに係る サプライチェーン・リスクの課題整理 及び その対策のグッドプラクティス集 2025（令和7）年6 月19 日 デジタル庁 〔ドキュメントの位置付け〕 Informative 参考とするドキュメント 〔キーワード〕 サプライチェーン・リスク、ビジネスサプライチェーン、サービスサプラ イチェーン、ソフトウェアサプライチェーン 〔概要〕 本書は、政府情報システムの関係者が政府情報システムにおけるサプライチェー ンに起因するセキュリティインシデント等の発生リスクを低減し、政府情報システ ムのセキュリティ水準を向上させることを目的として、政府情報システムに関連す る主要なサプライチェーン・リスクとそのセキュリティ対策を説明する。\n\n改定履歴 改定年月日 改定箇所 改定内容 2025年6月19日 - 初版決定\n\n目次 １ はじめに ......................................................... 1 １.１ 目的 ...................","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"本文（PDF／548KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/a547f9a6/20250630_resources_standard_guidelines_technical_report_01.pdf","page_from":1,"page_to":3,"char_count":1200},{"chunk_id":"8924e19b781c18e87de87f1d7774afd4_c1","doc_id":"8924e19b781c18e87de87f1d7774afd4","text":"................... 8 ３.１ 総合的なリスクアセスメントの実施 ............................ 8 ３.２ 委託先等との協力体制の強化 .................................. 8 ３.３ 継続的な監視と評価の重要性 .................................. 8 ３.４ インシデント対応計画の整備 .................................. 9 ３.５ まとめ ...................................................... 9 ４ 想定される主要なサプライチェーン・リスクと対策 .................. 10 ４.１ ビジネスサプライチェーン・リスク ........................... 10 1) 委託先における管理不備のリスク .............................. 11 2) 委託先における内部不正のリスク ........................","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"本文（PDF／548KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/a547f9a6/20250630_resources_standard_guidelines_technical_report_01.pdf","page_from":3,"page_to":3,"char_count":1200},{"chunk_id":"8924e19b781c18e87de87f1d7774afd4_c2","doc_id":"8924e19b781c18e87de87f1d7774afd4","text":"....................................................... 26 ４.３ 機器・ソフトウェアサプライチェーン・リスク ................. 28 1) 外部調達のソフトウェアに内在する脆弱性によるリスク .......... 28 2) マルウェア（悪意のあるコード）の混入によるリスク ............ 30 3) ハードウェアのセキュリティ侵害によるリスク .................. 32 4) ファームウェアのセキュリティ侵害によるリスク ................ 34\n\n1 １ はじめに 本書は、政府情報システムの機器調達等におけるサイバーセキュリティに係 るサプライチェーン・リスクについて理解を深め、適切に対応するため、その 課題整理とセキュリティ対策におけるグッドプラクティスを示す。 １.１ 目的 本書は「デジタル社会推進標準ガイドライン」におけるセキュリティに関す る技術レポートと位置づけており、政府情報システムの開発や運用業務に従事 する関係者に対して、政府情報システムの機器調達等","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"本文（PDF／548KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/a547f9a6/20250630_resources_standard_guidelines_technical_report_01.pdf","page_from":3,"page_to":5,"char_count":1280},{"chunk_id":"8924e19b781c18e87de87f1d7774afd4_c3","doc_id":"8924e19b781c18e87de87f1d7774afd4","text":"プライチェーン・リスクに関連する社会的な情勢や、サプラ イチェーン・リスクへのセキュリティ対策の必要性について言及するとともに、 サプライチェーン・リスクの分類とその定義について解説する。なお、第２章 は、第３章以降を読み進める際の前提となるため、留意すること。\n\n2 第３章では、サプライチェーン・リスクへの対応にあたって、どのような政 府情報システムにおいても対応が求められる実施事項を記載する。サプライチ ェーン・リスクへの対応にあたっては、まず、本章の内容を認識することに留 意すること。 第４章では、第２章の政府情報システムにおけるサイバーセキュリティ上の サプライチェーン・リスクの分類に従って、分類ごとに想定される、主要なサ プライチェーン・リスクの概要とそのセキュリティ対策を記述する。主要なサ プライチェーン・リスクの選定については、政府情報システムへの監査やセキ ュリティに関する支援を通じて特に重大な影響を及ぼす可能性や発生頻度が高 いと考えられるリスクや、世の中で発生した具体的なサプライチェーン関連の 事例を踏まえた。また、セキュリティ対策については、技術的対策だけではな ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"本文（PDF／548KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/a547f9a6/20250630_resources_standard_guidelines_technical_report_01.pdf","page_from":4,"page_to":6,"char_count":1140},{"chunk_id":"8924e19b781c18e87de87f1d7774afd4_c4","doc_id":"8924e19b781c18e87de87f1d7774afd4","text":"のサプ ライチェーン・リ 本書では、政府情報システムの機器調達、外部委託、ク ラウドサービス選定等におけるサプライチェーンに関す るサイバーセキュリティリスクを取り扱う。例えば、サ ードパーティ製の機器を調達する際の製造元に関するサ イバーセキュリティリスク、外部委託先の管理に関する\n\n3 用語 意味 スク サイバーセキュリティリスク、クラウドサービスの運用 に関するセキュリティリスクなどがある。\n\n4 ２ 政府情報システムにおけるサプライチェーン・リスクの概要 ２.１ サプライチェーン・リスクの情勢 政府情報システムに限らず、情報システムの構築・運用・保守においては、 サードパーティ製の機器やソフトウェアの利用だけでなく、業務委託や各種サ ービスの活用など、自組織のみで対応することが難しい場合に、専門の外部事 業者に依頼することがある。これらの外部事業者やその従業員はすべてサプラ イチェーンの一部と見なされる。特に近年ではクラウドサービスの利用が前提 となり、サプライチェーンが一層拡大している。 その結果、表２に示すように、サプライチェーンに起因するセキュリティイ ンシデントが多発し","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"本文（PDF／548KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/a547f9a6/20250630_resources_standard_guidelines_technical_report_01.pdf","page_from":5,"page_to":8,"char_count":1279},{"chunk_id":"8924e19b781c18e87de87f1d7774afd4_c5","doc_id":"8924e19b781c18e87de87f1d7774afd4","text":"業者に委託したが、その業者が許可なく海 外の業者に再委託し、個人情報が海外に渡っていたこと が発覚した。 （機密性の損失）\n\n5 ２.２ サプライチェーン・リスクへのセキュリティ対策の必要性 表２の事例が示すように、自らの組織や情報システムのセキュリティ対策の みならず、サプライチェーン全体のリスクも考慮した上で、適切なセキュリテ ィ対策を実施しなければ、結果的に自らにまで悪影響が及ぶことになる。その ため、政府情報システムにおいても、表３に代表されるサプライチェーン・リ スクに起因する大規模な攻撃や事故等に備えて、様々な観点で十分なセキュリ ティ対策を実施することが求められる。 さらに、様々な情報システムやモノが繋がる時代において、サプライチェー ン・リスクの影響は特定の機関に限定されず、複数機関、ひいては政府全体に まで波及する可能性を懸念し、多層でのセキュリティ対策を実施することが求 められている。 また、サプライチェーン・リスクは、経済安全保障分野においても想定され ている。 「経済施策を一体的に講ずることによる安全保障の確保の推進に関す る法律」 （令和４年法律第43 号）に","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"本文（PDF／548KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/a547f9a6/20250630_resources_standard_guidelines_technical_report_01.pdf","page_from":7,"page_to":9,"char_count":1250}],"avg_length":1204.384705882353,"k1":1.5,"b":0.75}