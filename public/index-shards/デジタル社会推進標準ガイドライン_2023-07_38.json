{"shard_id":"デジタル社会推進標準ガイドライン_2023-07_38","group":"デジタル社会推進標準ガイドライン_2023-07","chunk_count":50,"chunks":[{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c58","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"合と、 熟練者が 「あえて」 やってしまう違反行為とがあります。 6.2 意図しない使用エラーと、 意図的な使用エラー 人間は、外部環境からの刺激を認知し、それに基づいて判断し、具体的な行動をとるという一連のプロセス に従って日常的に作業を行っています。この 「認知→判断→行動」 の過程を構造的に理解することで、使用エ ラーが、どこで・どのように発生するのかを明確に可視化することが可能になります。 使用エラーが 「認知・判断・行動」 のどの段階で発生したのかによって、端的にいえば 「うっかり」 やってし まったのか 「あえて」 やってしまった違反行為なのかで、対策は大きく異なってきます。﻿ ●過失に基づくもの （うっかり） ●記憶の錯誤 ●認知ミス ●判断ミス ●行動ミス ●知識や技量の不足 ●意図的・故意的なもの （あえて） ●近道行動 ●省略行動 ●違反・不遵守\n\npage 55 6. 使用エラーのメカニズム 6.3 「う っかり 」 や 「あえて」 はどのようなときに発生するのか 人が 「認知し、判断をし、行動する」 プロセスをモデル化することで、 「うっかり」 や 「あえて」 ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":55,"page_to":56,"char_count":1298},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c59","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"い） 与えられた状況に対する認知が不完全 （正しく状況を理 解できていない） で間違った行動を取ってしまう。 スリップやラプスは本人が意図せず無自覚に発生してしまうエラー （うっかり） です。これに対して 「ミステ イク」 は 「自覚的」 に （あえて） 発生するエラーです。なお、 エラーではないものの対策が必要なものに 「違反」 が あります。正しい手順を知っているが、自覚的に逸脱する行為です。 人の認知行動が熟練してくると、目標を達成するための判断・行動の一連の流れが自動化され、あたかもプ ログラムであるかのように意識しなくてもできるようになってきます。これをスキーマと言います （ぼーっと考 え事をしていても家に帰ってこられるのはスキーマが構築できているおかげです） 。ATSやGEMSでは、スキーマを起 動させる刺激と働きに注目します。スキーマは単独で機能するわけではなく、他のスキーマを刺激したり、複 数のスキーマが自動的に活性化したりします。スリップは、適切なスキーマが存在しない （知識不足） か、誤っ た刺激が波及してしまった場合に発生すると考えます。次節からは、典型的な使用エ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":56,"page_to":57,"char_count":1195},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c60","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"6.3.3 データ駆動型エラー （目の前のことに引っ張られる） いつもやっている行動 （熟練行動） が、与えられた刺激に反応してすぐ実行されてしまうことで発生するエ ラーです。﻿ ●電卓アプリで、電話番号を押してしまった 6.3.4 乗っ取り型エラー （いつもの行動に引っ張られる） 直近で実施した （あるいは習熟している） 共通した要素を持つ現象や概念 （スキーマ） にとらわれてしまうエラーです。﻿ ●郵便局に寄ってから帰ろうと思っていたのに、ぼーっと歩いていたらそのまま帰ってきてしまった ●顔を洗おうと水をだして、つい石鹸を手にとってしまった 6.3.5 連想活性化エラー （頭で考えたことに引っ張られる） 連想しやすい概念が、たまたま頭の中で呼び出されてしまったために引き起こされるエラーです。 ●いうべきではないと思ったことの方を口に出してしまった 6.3.6 活性化消失エラー （物忘れ） 行為の元になった意図が消失してしまい、なぜその行動をしようとしていたのか分からなくなるエラーです。 ●辞書を開いた途端、何を調べようとしていたのか忘れた\n\npage 57 6. 使用エラーのメカニ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":57,"page_to":58,"char_count":1264},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c61","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ミノモデル 作業者の不注意や教育不足といった初期要因が、環境的・組織的要因を介して事故へと至る一連の因果 関係を、倒れるドミノの列になぞらえて説明します。 ●スイスチーズモデル スイスチーズモデル多層的な防御システムを構成している各々の防御システムに （万が一） ﻿“穴”（＝防御 の弱点） が空いていると仮定しても、 それらの穴が同時に重ならなければ、 事故は発生しないという構造 を示しています。これは、組織的・技術的・人的な多重の防御層とエラーの関係を強調するものです。 重大事故の発生を防ぐためには、各段階で生じるエラーの連鎖を早期に断ち切ることが効果的だ、というの が基本的な考え方です。例えば、 フェイルセーフ ［8.3.2］ やフールプルーフ ［8.3.3］ といった安全設計の考え方、 あるいはリスクアセスメントの基本的な構造は、このエラーチェーンモデルの前提に立っています。特にユー ザビリティの観点からは、システムやUI設計の中でユーザーのエラーが他の要因と連鎖しないようにする、ま たは早期に検出・是正できる仕組みを組み込むことが求められます。\n\npage 58 6. 使用エラ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":58,"page_to":59,"char_count":1170},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c62","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"構造が複雑で、全体像の把握が困難なとき ●組織課題や伝統のような非技術的な側面が重視されてしまうとき こうした状況では、 エラーや事故の発生を 「単一の線形因果関係の結果」 として捉えるのではなく、 システム 全体の構造、 相互作用、 組織的文脈等を含めて捉える視点が求められます。そのため、 近年ではよりシステミッ クなアプローチに基づく概念モデルやリスクアセスメント手法の開発が進められています。例えば、STAMP （Systems-Theoretic Accident Model and Processes） ［9］ やFRAM （Functional Resonance Analysis Method） 等の手法 は、複雑な社会技術システムを対象とした新しい安全評価モデルとして注目されています。 とくに原子力、航空、医療等の複雑系を扱う分野では、エラーチェーンモデルのみで安全性を語ることは少 なくなっており、多層的な要因を同時に扱える枠組みの必要性が高まっています。\n\npage 59 7. 使用エラーの可視化・分析 7 使用エラーの可視化・分析 ここでは使用エラー等の要因の可視化・","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":59,"page_to":60,"char_count":1155},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c63","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"「真因と思われる原因まで突き止める」 のが目標です。ポイントは 「単に5回 なぜを繰り返す」 のではなく 「掘り下げられるかどうか」 です。掘り下げた結果が 「真因」 かどうかは、以下の ような基準で判断します。﻿ ●その原因に対する対策が繰り返されうるものの場合、それは真因ではない （例： 「うっかり忘れ」 の原因を 人に求めると 「指差し確認をする」 のが対策になりますが、 再発を防げません。この場合真因を 「うっかり忘れに対 応できなかったバリデーションの不備」 に置くと対策では再発を防げます） ●他責にせず、 対策が立てられうる真因を探す （例えば 「雷が落ちたから」 というのは雷自体を防ぐことができな いという意味において、他責的思考です） ●現実に対応できるか十分に確かめる\n\npage 60 7. 使用エラーの可視化・分析 7.1.3 SHEL 分析モデルとSHELL 分析モデル エルウィン・エドワーズによって提唱されたSHEL分析モデル （Edwards,﻿1972） を、フランク・H・ホーキン スが拡張したのがSHELL分析モデル （Hawkins,﻿1975） です。","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":60,"page_to":62,"char_count":1295},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c64","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"使用エラーの可視化・分析 SHELL分析モデルでは、要素間の相互作用が視覚的に強調されています。 1. L-H (Liveware-Hardware) 人間と機械の相互作用。 例：操作しやすいインタフェースや、誤操作を防ぐ設計。 2. L-S (Liveware-Software) 人間とソフトウェア （手順やマニュアル） の相互作用。 例：理解しやすいマニュアルの必要性、システムエラーの予防。 3. L-E (Liveware-Environment) 人間と環境の相互作用。 例：適切な照明、騒音やストレスの低減。 4. L-L (Liveware-Liveware) 人間同士の相互作用。 例：チームワーク、コミュニケーション、役割分担。 それぞれの状態や関係は刻々と変化していきます （例えば、人間は疲弊します） 。ある相互作用のファクターが 変化したときには、他の関係にも影響がある （他の影響も考慮しなければならない） と考えるのです。﻿ 7.2 規格に基づく アセスメントの枠組み 国際標準には、世界中の専門家の良質な知見が集められています。規格に基づき、アセスメントの基本的な 枠","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":62,"page_to":63,"char_count":1264},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c65","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"中に発生したインシデントに、使用エラーが関与している可能性がある場合には、再 発防止と設計改善を目的として、構造的・認知的・組織的な観点から原因分析を行う必要があります。 このとき重要となるのは、インシデントに関与した個人のミスを単純化して捉えることを避けることです。こ こで 「自分が悪かった」 「なぜ〇〇できなかったのか」 といった自責的・後知恵的な評価は、原因の本質を見誤 るおそれがあります。 後述するCAST （Causal Analysis based on STAMP） ［9.3］ は、分散的な意思決定が行われる複雑なシステムで、 このような後知恵バイアスを回避し、インシデントの因果構造を体系的に明らかにする手法として有効です。 CASTでは 「誰が悪かったか」 を問うのではなく、 「なぜその時にそうするのが合理的だったのか」 を明らかにす ることで、予防可能な構造上の課題を抽出するアプローチです。あわせて参考にしてください。 簡易の原因調査を行う場合であっても、以下のようなポイントに注意しましょう。 なるべく多くの情報を収集する インシデントに関わった関与者について、それぞ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":63,"page_to":64,"char_count":1263},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c66","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"メント ユーザビリティデザインに取り組むべき最大の理由のひとつが、労働災害や個人情報漏えい等のインシデン トの防止です。過去、多くの情報システムや工場、産業機械や航空機等の事故が、オペレーターの使用エラー を最終的なトリガーとして引き起こされてきました。令和5年の労働災害発生状況調査では、 機械等による 「は さまれ・巻き込まれ」 の死傷者数は13,928人 （死者108人） と報告されています。こうした事故を防いだり被害 を軽減したりする上でも、ユーザビリティの確保は非常に重要です。﻿﻿﻿﻿﻿ 8.1 リスクマネジメントの主要概念を理解する 8.1.1 脅威 （ハザード） とリスクとはなにか ユーザビリティ上のリスクとは、発生すると、情報システムの提供者、利用者、その他のステークホルダー にとって意図しない結果、なんらかのアクシデントによって脅威 （ハザード） がもたらされることを指します。﻿ 脅威は必ずもたらされるわけではなく、何らかの事象の結果として引き起こされる不確定性を持っています。 そこで近代以降の科学は、脅威がもたらされる可能性をリスクとして捉え、コントロールしようとして","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":64,"page_to":65,"char_count":1211},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c67","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"とリスクマネジメントのプロセス 安全性の評価や対策の基本的な考え方には、決定論的評価 （DSA） と確率論的評価 （PRA） があります。やり方 が決まっていれば同じ結果にたどり着くのが決定論、ランダムに事象が発生し同じ結果にたどり着くとは限ら ないのが確率論です。﻿落雷による停電やシステムの故障等の 「予想外の出来事」 「たまたま起きること」 が脅威 をもたらすことがあり、それらは確率論的です。﻿ 安全評価や対策を行う場合は、決定論的評価 （DSA） と確率論的評価 （PRA） を、検討対象課題に応じ組み合わ せて、 リスクを定量的に評価しながら対策を考えていくのが基本的なアプローチです （ただし、 情報システムの安 全評価・設計においてはこのアプローチだけでは限界があることを9章以降で見ていきます） 。﻿ 決定論的評価 確率論的評価 確定的事象・脅威が対象 偶発的事象・脅威が対象 特定の条件下でのシステムの振る舞いのプロセスを 評価し対策を行う システムやプロセスが不確実性の影響を受ける場合 に、その結果の発生確率を評価し対策を行う 確実性の高い結果が発生するのが前提。 特定の操作","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":65,"page_to":66,"char_count":1276},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c68","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"トレランス 使用エラーをゼロにすることはできませんが、訓練や意識付けによってエラーの発生を起きにくくすること はできます。これを 「エラーレジスタンス」 といいます。また、 仕組みでの工夫によって、 使用エラーが発生し ても事故に結びつかないようにすることを 「エラートレランス」 といいます。﻿ 8.3.2 フェイルセーフ エラーレジスタンスに似た概念に、フェイルセーフとフールプルーフがあります。エラーが発生しても安全 側に収束するように工夫することをフェイルセーフといいます。フェイルセーフには以下のような例がありま す。﻿ ●倒れると停止するストーブ ●ドアを開けると止まる電子レンジ ●停電すると自動的に下がる踏切の遮断機 8.3.3 フールプルーフ フールプルーフとは、全く使い方を知らない人が異常使用をしても問題を引き起こす機能を働かせない仕組 みのことです。﻿ ●ブレーキを踏んでいないとドライブモードに入らない車のギア ●両手で操作しないと使えない裁断機 ●異なる端子は接続できない形状になっている 防ぐべきハザードがシンプルで発生条件が特定できていれば、誤使用によりエラーが誘発さ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":66,"page_to":67,"char_count":1281},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c69","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"い事象 （トップイベント：Top﻿Event,﻿TE） をツリーの頂点に設定し、それがどのような 要因によって引き起こされる可能性があるかを論理的な因果構造として視覚的に表現します。 例えば、 「個人情報の漏洩」 というトップイベントに対して、 「外部からの不正アクセス （事象A） 」 または 「内 部者による誤操作 （事象B） 」 という原因が考えられる場合、 それぞれをORゲートで接続します。さらに、 「誤操 作 （事象B） 」 が 「研修未実施 （事象C） 」 と 「確認手順の欠落 （事象D） 」 の両方によって引き起こされるときは、 AND ゲートで接続されます。 重大事故（TE） 事象A 事象B 事象C 事象D OR AND 図8.2 フ ォ ール ト ツ リ ー図の例。 重大事故 （TE） は事象A又は事象Bが発生 し たと き （OR条件） 発生 し、 事象Bは事象CとDの 両方が発生 し たと き （AND条件） に発生す る。\n\npage 67 8. 安全設計とリスクマネジメン ト このようにFTAでは、トップイベントに至るまでの原因構造をツリー状に描き、構造上の弱点","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":67,"page_to":68,"char_count":1290},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c70","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ンを押す （スリップ） 。 ●ユーザーが操作手順を省略する （違反） 。 ●マニュアルが不明瞭で操作手順を誤解する （ミステイク） 。 これらの事象を因果構造としてツリー図で表現することで、それぞれのエラーがトップイベントにどうつな がるかを可視化でき、リスクシナリオの評価ができるようになります。ただし、現代の情報システムにおける FTA適用では、以下の制約があることを認識しておく必要があります。 定量的評価の限界 情報システムでは、ハードウェアのような故障率データが存在しないため、確率計算は参考値に留まります。 動的な性質 利用者の学習やシステムアップデートにより、エラー率は時間とともに変化します。 文脈依存性 同じ操作でも、状況や利用者の振る舞いにより異なるエラーが発生します。\n\npage 68 8. 安全設計とリスクマネジメン ト ツリー図の作成例 各事象を中間事象とした、AND／ORゲートによって構造化されたFTAを作成します。 重大事故（TE） 直接的なデータ損失 システム状態の不整合 OR OR OR AND 重要業務プロセスの中断（データ損失を伴う） 不完全なトランザクシ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":68,"page_to":70,"char_count":1273},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c71","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"活かすこともできます （次節のFMEAの分 析例で、優先順位付けの事例を紹介しています） 。\n\npage 69 8. 安全設計とリスクマネジメン ト 8.6 FMEA （Failure Mode and Effects Analysis） 故障モード影響解析 （FMEA） は、想定されうる故障やエラー等の一覧を作成し、それぞれの影響度や発生確 率に基づいて優先的に対策すべき項目を特定する手法です。使用エラーが引き起こすトラブルを事前に抽出し、 リスクを定量的に把握する際に有効です。 8.6.1 FMEAの作業手順 作業プロセスの明確化 システムや業務の一連の手順 （分析の対象を細かく区切る） で具体的な操作や手順 （作業プロセス） を洗い出す。 想定されうるエラーの列挙 作業プロセスごとにエラーが起きうるもの （故障モード） を列挙する。 影響評価 エラーによって引き起こされる結果 （波及事故） を評価し、回復に要するコストや発生確率を基準として 「致 命度」 を算出する。表に示した例では、回復コストと発生確率をかけ合わせて致命度を評価しています。 観察による補強 （可能な場合） 実際","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":69,"page_to":71,"char_count":1170},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c72","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"HAZOP （HAZard and OPerability Studies ） FTAやFMEAと並びよく使われるリスク解析方法です。HAZOPでは 「ない」 「反した」 「よりも早く」 といっ た 「設計意図・通常の利用方法」 からのずれを 「ガイドワード」 として用意してブレインストーミング等を行い、 分析を行う手法です。プロセスを分析の対象とするノードに分解し、ノードごとに分析を行います。﻿ ●ノード1：ログイン認証 ●ノード2：申請フォーム入力 ●ノード3：添付書類アップロード ●ノード4：内容確認 ●ノード5：送信・完了 元々は化学プラントの安全設計のために開発された手法なので、ユーザビリティの解析に使うためには、ガ イドワード等を改良したものを使います。﻿ ガイドワード エラー 責任 発生事故 抜かす ステップを抜かす 使用者・使用状況 手続が完了できない 繰り返す フォーム でクリックを繰り返す 両方 情報が重複し て送信されて しまう 忘れる 提出を忘れる 使用者・使用状況 手続が完了できない 急いで 急いで作業する 使用者・使用状況 重要な情報を見落とす ゆっく り ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":71,"page_to":72,"char_count":1230},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c73","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"的評価 （Probabilistic﻿Risk﻿Assessment:﻿PRA） です。PRAは、 リ スク事象の発生確率およびそれに伴う影響を定量的に評価し、リスクに関する意思決定を合理的に支援するこ とを目的としたアプローチです。PRAは特に、原子力施設における安全評価の分野で長年活用されており、複 雑なシステムの構成要素がどのように相互作用してリスクに至るかを把握する上ではある程度有効です。 ただ、以下のような特徴を持つソフトウェア開発プロジェクトでは、PRAは導入に一定の制約がある手法で あり、本ガイドブックでは深く踏み込みません。 ●統計的・定量的な情報が十分に蓄積されていない ●対象システムが動的かつ複雑であり、因果関係が明確でない ●未知のリスクや設計初期段階での不確実性に対応したい ●人的要因やソフトウェアの設計ミス等定量化が困難な要素を扱いたい ●デザインプロセスへの柔軟な統合が求められる PRAは 「原因と結果のチェーン」 を重視しているため、 過去の事故データやイベントツリー分析、 フォールト ツリー分析を使ってリスクを定量的に評価していきます。このため、構成が変","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":72,"page_to":73,"char_count":1296},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c74","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"生確率を評価し、 リスクの低減策を導くことを目的とした評価活動のことです。 従来の確率論的リスク評価 （PRA ［8.8］ ） では、 人の行動を確率的に扱うことが前提であり、 複雑な認知判断や 環境要因の影響までは十分に捉えきれないという課題があります。HRAはこうした限界を補い、人的要因をよ り深く理解しながら、安全設計に反映させるための枠組みです。HRAはいくつかのアプローチに分けられます。 ●第1世代のアプローチ 主に作業手順に従った行動の逸脱確率を、経験的データに基づいて推定する手法です。代表的なものに、 THERP （Technique﻿for﻿Human﻿Error﻿Rate﻿Prediction） やSLIM （Success﻿Likelihood﻿Index﻿Method） があります。 ●第2世代のアプローチ 人間を意思決定主体としてとらえ、作業コンテキストや認知過程を重視するモデルです。心理学や認知 科学の知見を取り入れた手法として、 CREAM （Cognitive﻿Reliability﻿and﻿Error﻿Analysis﻿Method） やATHEANA ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":73,"page_to":74,"char_count":1285},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c75","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ト 8.10 HRAとFTAの併用による使用エラーの分析例 HRAは人的エラーの発生確率や背景要因を評価する手法であり、FTA （Fault﻿Tree﻿Analysis） はリスク要因の論 理的構造を視覚化する手法です。両者を組み合わせることで、リスクの定量評価と因果関係の構造化を同時に 行うことができます。以下に、病院における薬剤投与業務を例に、HRAとFTAの併用による分析の手順を示し ます。 8.10.1 使用エラーの分析と確率評価 （HRA） 病院の薬剤投与システムにおいて、 以下のような使用エラーが想定されるとします （※確率は例示です） 。これ らのエラータイプ （発生要因ベース） には、 ［6.3］ で紹介したラスムッセンのSRK （Skill-Rule-Knowledge） モデル や、J・リーズンのGEMS （Generic Error-Modelling System） を基盤として用います。 ●スリップ （誤選択） ：看護師が正しい薬剤を認識しているが、隣の薬剤を手に取る （確率: 0.1） （注記） 。 ●ラプス （忘却） ：看護師が指示通りの時間に薬を投与し忘","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":74,"page_to":75,"char_count":1258},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c76","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"造を持ち、他のシステムやサービスとの相互接続性が高まっていま す。例えば、複数のWebサービスが連携したり、新たな機能が継ぎ足されて運用されたりする中で、個々の設 計者が想定しなかった相互作用によって事故や障害が引き起こされるリスクが増加しています。 従来の安全工学 （Safety-I） は、 「事故の防止」 に焦点を当て、個別の故障や人的エラーを排除することで安全 性を確保しようとしてきました。しかし、ホルナゲルらが提唱するSafety-IIのパラダイム （Hollnagel,﻿2006） で は、 「うまくいくことの確保」 に重点を置き、システムの適応能力と回復力 （レジリエンス） を重視します。 背景には、現代的な情報システムが抱える 「複雑性」 と 「密結合性」 があります。特に以下のような状況では、 従来型の因果分析や故障前提のアプローチでは対応が困難であり、これまでに紹介してきた 「個別のエラーや 故障の原因と結果」 に注目するリスク分析手法では不十分です。 ●複数のコンポーネントや組織が関与し、全体像が見えにくいシステム ●ヒューマンファクターや組織的要因が影響するシステ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":75,"page_to":76,"char_count":1216},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c77","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"AMP/STPA STAMP/STPAは、 レブソンが提唱したシステム思考と制御理論に基づいた安全分析手法 （Leveson,﻿2012） です。 システムの構造や制御の失敗に着目し、ヒューマンファクター （人的要因） や組織要因も含めて全体的な安全性 を評価できることが特徴です。特に、 ソフトウェアの影響が大きい現代の複雑なシステムにおいて、 STPAは有 効な分析手段として注目されてきました。 9.1.1 STAMP/STPAのキーコンセプト STAMP/STPAは、 事故の発生を個別要素の故障ではなく、 システム全体における安全制約 （Safety﻿Constraints） の不備として捉える枠組みです。ここでいう 「システム」 とは、 情報システムそのものに限らず、 関係組織、 運 用者、 規則や社会的要請を含んだ全体構造を意味します。STAMPでは、 これらの構成要素が相互作用する構造 の中で、安全制約をどのように維持するかを分析対象とします。システム全体の構造を制御の視点からモデル 化する際には、主に階層的な安全制御構造を用いた整理を目指します。 これは、 政策決定層、 組","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":76,"page_to":77,"char_count":1114},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c78","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"STPAではそのような複雑な関係 性も柔軟にモデル化することができます。関係者間での柔軟な思考や創発を促すことを念頭に置きながら、シ ステムの特性に応じて制御構造の定義に取り組むことが求められます。\n\npage 76 9. システム思考に基づく 安全設計のアプローチ さてここまで 「コントローラー」 とは何かを具体的に説明してきませんでしたが、 以下の要件を満たしている ものがコントローラーです。 ●なんらかの制御アルゴリズムを持っている （STAMPの文脈では特に、安全のための制約、判断） ●他のコントローラー （システム） に影響を与えることができる （コントロールアクションの出力） ●システムの状態を観測することができる （フィードバックの受信） ●コントロール対象となるプロセスに対応したプロセスモデル （どんな状態にあるときになにができるのか、 状態変数とプロセスの遷移） を持つ STAMPを安全の設計や解析に応用するための手法がSTPAです。 「十分な情報かつ適切なタイミングで」 （適切 性及び適時性） 各コントローラーがコントロールアクションを行い、その結果がコントローラー","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":76,"page_to":77,"char_count":1175},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c79","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ョンが実行されたことが不適切 （例：誤入力） ●コントロールアクションが実行されなかったことが不適切 （例：必要な操作を行わない） ●実行のタイミングが早すぎる／遅すぎる ●順序の誤りや文脈誤認によって、誤った判断がなされる これらのUCAに注目することで、例えば 「誤入力」 「確認漏れ」 「判断の混乱」 等の使用エラーを、システムの 構造やフィードバックループとの関係で可視化することができます。\n\npage 77 9. システム思考に基づく 安全設計のアプローチ 9.1.4 システムの実際の挙動とプロセスモデルのずれを分析する STAMPでは、 事故の多くは 「意図的な違反」 よりも 「合理的に見えた行動が結果として不安全だった」 という 構造に起因すると考えます。これは、 コントローラーが保持するプロセスモデル （＝対象の理解や予測） が、 現実 のシステム挙動とずれていることで生じます。 STAMPにおけるプロセスモデルの不整合分析は、 認知工学におけるメンタルモデル研究と類似の課題を扱い ますが、理論的基盤は異なります。プロセスモデルは制御理論に基づく 「制御対象の内部表現」 ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":77,"page_to":78,"char_count":1277},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c80","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"慮に入れたデザイン及び開発を行うことができます。また、 本手法はセキュリティインシデントを防ぐための手法としても活用できます。 本セクションでは、基本プロセスとデザインプロセスへの導入のヒントを紹介します。本手法について詳し く知りたい方は、 IPAが発行しているガイドブックや民間の解説書を参考にしてください。IPA版ガイドブック には、日本の利用者向けに適応した手順、分析例等が網羅されています。\n\npage 78 9. システム思考に基づく 安全設計のアプローチ 9.2 STPAの基本プロセス ここからは、STAMPに基づいて事故やハザードの予防を目的とした安全解析手法であるSTPAの基本的なプ ロセスを見ていきます。主に以下のステップで構成されています。 ●分析目的の明確化と安全目標の設定 ［9.2.1］ ●コントロールストラクチャ （Control Structure） の可視化 ［9.2.2］ ●安全でないコントロールアクションを抽出する ［9.2.3］ ●安全でないコントロールアクションが引き起こされる要因やプロセスを特定する [9.2.4] ●安全制約を満たすための制御構造","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":78,"page_to":79,"char_count":1271},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c81","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"準 ●マニュアルや運用ルールの変化 ●緊急時対応の柔軟性 残念ながら （どんな手法においてもそうですが） 「なにが安全なのか」 「何を回避するべきなのか」 を定義しきる、 簡単で完全な手法はありません。本ガイドブックの前半でも示したように、ユーザビリティは使っているとき の文脈や環境、利用者の知識等によって影響を受けます （ハザードランプの示す意味が文脈によって変わる例を思い 出してください） 。また、ここでいう 「システム」 には、 ［9.1.1］ でも示したように、安全性を担保する組織や人 も 「システムの構成要素」 として含んでいます。組織文化やオペレーターの 「慣れ」 や経年変化等によっても安 全は脅かされうるのです。 例えば空港の航空管制を例に考えてみましょう。航空管制は、出域管制 （離陸） 、入域管制 （着陸） 、タワー管 制 （滑走路管理） といった複数の制御主体 （コントローラー） が協調して運用されています。出域管制は離陸機の安 全を、入域管制は到着機の安全を受け持つと （ここでは試しに） 定義するとします。このときに各管制が最も注\n\npage 79 9. システム思","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":79,"page_to":80,"char_count":1208},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c82","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ならない」 「常に○○を確認する必要がある」 といった形で、 具 体的かつ制御的に定義されるべきものです。安全制約を定めるには、こうした安全性に影響を与える要素や文 脈等の全体像を十分に洗い出し、関係者間で、どのような目標に向かって設計を行うのか合意していく必要が あります。 自動運転システムの安全目標の例を見てみましょう。自動運転車両では、以下のような包括的かつ現実的な 安全目標が考えられます。 ●交通状況に関係なく安全に運転を維持する ●人が乗り降りしているときにも、事故や挟まりが起きないよう制御する ●万一事故を起こした場合も、乗員・被害者・歩行者の安全を最優先する ●災害時・緊急事態下では、乗員及び周囲の人の安全を確保する動作に切り替わる これらの目標は、 「事故を起こさない」 ことだけでなく、 「事故やハザードが発生しても被害を最小限に抑える」 という視点から設定されるべきです （＝フェイルセーフやリカバリの観点を含む） 。また、 以下のようなハザードの 管理体制上の曖昧さを見逃さず分析することも重要です。 ●コントローラーの誰も責任を負っていないハザード ●複数のコントロー","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":80,"page_to":81,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c83","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"rolled Process） コントローラーの指示によって振る舞いが変化する対象。車両、システムUI、現場オペレーター等。 ●コントロールアクション （Control Action） コントローラーが出す命令・操作指示 （例： 「ドアを閉める」 「エアバッグ展開」 等） ●フィードバック （Feedback） コントロール対象プロセスからコントローラーに返る情報 （例： 「ドアが閉じた」 「エンジン異常あり」 等） ●コントロールアルゴリズム （Control Algorithm） プロセスモデルと入力に基づいて、どのアクションをいつ実行するか判断する内部ロジック コン トローラー 指示（コン トロールアクション） フィードバック コン トロール対象となる システムのふるまい（被コン トロールプロセス） コン トロール アルゴリズム プロセスモデル 出力 入力 図9.2 コン ト ローラーと コン ト ロール対象プロセスの相互作用を示す基本的なモデル。 また、各コントローラーは内部に （コントロール対象プロセスに対する） プロセスモデル （Process﻿Model） を持ち、 プロ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":81,"page_to":82,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c84","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ウェア、監視者 ●コントロール対象プロセス：車両のブレーキ、アクセル、ステアリング ●フィードバック：センサーからのデータ （車速、車間距離、現在位置等） 。 自動運転ソフ トウェア センサー群 意思決定者 アクチュエータ制御システム 運転者（利用者） 速度制御 統合制御 ブレーキ 速度センサー 測位センサー 車載カメラ アクセル 車両の物理的な動作 ステアリング 経路計画 障害物認識 介入（コン トロールアクション） 制約条件 緊急停止・回避行動要求 目標軌道 加減速要求 目標速度 自動車の状態をフィードバック 制動・加速・操舵指示 天候や路面状況等の外部要因 制御 自動車・周辺環境の状態を フィードバック 制御状態をフィードバック 計測 コン トロール対象プロセス 図9.3 自動運転を例と し た制御構造図 （CS図） の例。 制御構造図の作成は、単なる図解作業ではなく、関係者間で 「安全性とは何か」 「制御はどう行われているか」 を共有 ・ 可視化する重要なコミュニケーションツールにもなります。この図に基づいて、 次のステップでは 「非 安全なコントロールアクション （UCA） ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":82,"page_to":83,"char_count":1192},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c85","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"：停止線を越えた後にブレーキがかかる、信号よりも早く発進する。 ●④ アクションが必要な時間よりも長く／短く続く 例：機首を下げ続けたまま戻らない、加熱処理が途中で停止する。 このような形式で分類することで、操作の不在・過剰・不適切なタイミング・時間といった観点でリスクを網 羅的に洗い出すことができます。例えば、自動運転車のコントロールアクションを想定すると、次のような組 み合わせが考えられます。 コントロールアクション （CA） 非安全な実行例 （UCA） アクセルを踏む 危険な状況でアクセルを踏んでしまう （②） ブレーキをかける 必要なときにブレーキが作動しない （①） 方向を変更する 変更のタイミングが遅れ、衝突する （③） アラートを表示する 表示が早すぎ／遅すぎ／表示されない （①〜③） 非安全なコントロールアクションの洗い出しには、HAZOP ［8.7］ で紹介したガイドワードを応用することで、 網羅的な検討がしやすくなります。例として以下のようなキーワードが使えます。 ●Not executed （実行されない） ●Too early / Too late （早すぎる／","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":83,"page_to":84,"char_count":1202},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c86","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"因 （Hazard Causal Factor: HCF） 、そしてそれがどのような過程で損害につながるのか （Hazard Scenario: HS） を特定し、安全 制約を強化するための設計改善へとつなげていきます。 HCFは、UCAが発生してしまう背景にある構造的、認知的、プロセス的な原因要因、組織運用等、幅広い範 囲で発生する制御上のギャップを意味します。例えば次のような事象が該当します。 ●コントローラーのプロセスモデルが実状と食い違っている ●入力情報が誤っている、または不足している ●コントロールアルゴリズムが適切でない ●フィードバックが遅延／欠落している このような原因が、コントロールアクションの誤りや判断ミスを引き起こすことで、結果としてハザードを誘 発します。注意すべきは、人間の行動は静的なアルゴリズムではなく、状況やフィードバックに応じて動的に 変化するという点です。システムと対話するオペレーターは、システムの反応を見て判断を変えたり、ルール を補完的に解釈することがあります。ここで、オペレーターに正常性バイアスが働いたり、システムイメージ を適切に認知できてい","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":84,"page_to":85,"char_count":1292},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c87","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"スモデル 通信エラーで自動運転がコントロールアクション を送信できない フィードバックの欠落／制御経路の脆弱性 制御の遅延により危険回避が間に合わない リアルタイ ム処理不足、制御設計の非現実性\n\npage 84 9. システム思考に基づく 安全設計のアプローチ HCFを元に特定されたリスクを軽減させるため、設計を見直します。 ●安全制約の再評価・強化 冗長化、フェイルセーフの導入等を検討します。 例：センサーの二重化、予備系の切り替え設計 ●制御構造・フィードバック経路等のコントロールプロセスの改良 情報伝達の信頼性向上、監視強化等を検討します。 例：ソフトウェアの状態監視とリカバリプロセスの追加 ●人間の動的な変化に配慮した設計 メンタルモデルの明示等のUXデザイン、UIデザインの再検討を行います。 例：フィードバック情報の可視化、リハーサル機能の導入 ●組織・責任の可視化とルール整備 責任の空白や競合をなくす構造を設計に埋め込みます。 例：複数部署が関わる場合の安全チェックポイントの明示化 HCFは 「なぜUCAが起きたのか」 を構造的に説明する鍵であり、 HSは 「それがどう損","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":84,"page_to":86,"char_count":1249},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c88","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ドを定義する 例：患者への誤投薬、サーバーダウン、列車の遅延﻿等。分析対象システムの境界と発生した事故の詳細 を明確化する。 ●安全制約を明らかにする 事故防止のために本来維持されるべきだった制約を特定する。 ●安全制御構造を可視化・文書化する 制約がどう破られたか、関与したコントローラーの制御構造を明らかにする。 人的／システム的コントローラー、コントロールアクション、フィードバックの有無など。 ●各コントローラーのプロセスモデルと認知状況を分析し、安全制約違反 （欠陥） を特定する 人がコントローラーであれば 「合理的に思えた判断、その要因は何だったか」 、 「情報に欠落や誤認はな かったか」 。 ●組織的・設計的な背景要因 （HCF） を抽出する 物理プロセス、技術・運用、組織・管理、政府・規制の各レベルで要因を特定する。 ●改善策・再発防止策を導出する 大枠の手順はSTPAで紹介したものと同じなので、ここでは詳説しませんが、ユーザビリティ確保の観点から 重要なポイントを紹介します。 9.3.2 CASTの観点をユーザビリティ テストで援用する CASTの観点は、ユーザビリティテ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":86,"page_to":87,"char_count":1262},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c89","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ィードバックループは途切れていなかったか？ （コミュニケーションミスマッチ） ●組織として、そのコントロールアクションをサポートできていたか？ ●手順・権限・責任は適切に分担されていたか？ STAMPに基づく安全設計では、 STPAによる事前の予防的分析と、 CASTによる事後の因果構造分析を組み合 わせることで、 設計と運用の間に連続性を持たせ、 より強固な安全文化の構築を目指すことができます。CAST で明らかになった以下のような事象は、STPAのフィードバックとして再利用することもできます。 ●安全制約の不備：新しい制約の追加 ●認知・プロセスモデルの誤り：人的要因をより深く反映したモデル化 ●コントローラー間の責任のあいまいさ：制御構造の再設計 STPAやCASTで明らかになった非安全な制御構造や要因を一度限りの対応で終わらせず、 システムや組織そ のものが学習し、より適応的な安全性を構築していくためには、 「ダブルループ学習」 の考え方が重要になるこ とも覚えておきましょう。これは、事故やインシデントの発生時に、単に行動 （例：手順やUI） を修正するだけ ではなく、その行動","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":87,"page_to":88,"char_count":1292},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c90","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"うな要素を明確に定義しておく必要があります。 ●提供しようとしている製品・サービスの特性とリスク特性の把握 （パフォーマンス観察・評価） ●安全な状態とはなにかを組織内で定義し、共有する ●安全目標の達成に向けて、どのような情報を、どのように活用して判断を下すかという意思決定の流れ （合意形成のための組織的プロトコル） を整備する ●人的・財政的リソースを確保する 図10.1 RIDMのプロセス。 安全目標に対し て のパフ ォ ーマ ン スを観測 ・ 評価し、 把握された リ スク特性に基づいた意思決定、 実行のサイ ク ルを繰り 返す 。 近年の安全工学においては、 単に 「事故やインシデントを防止する」 ことを目標とするのではなく、 発生を前 提とした 「安全のコントロール」 （Safety-II） へと発想がシフトしています。つまり、 失敗をゼロにすることより も、失敗が起きても被害を最小限に抑えるよう、システムの構造を設計することが重要とされています。第９ 章の冒頭でも述べたように、使用エラーやハザードを排除するのではなく、 「うまく対処できる」 適応能力と回 復力 （レジリ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":88,"page_to":89,"char_count":1237},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c91","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ず、 合理的な判断の中心要素として位 置づけるプロセスです。RIDMの特徴は、 単なる 「安全第一」 ではなく、 「目的を達成しながらリスクをどのよう に受容・制御するか」 を評価し、複数の選択肢の中から、最も妥当で実行可能な解を選ぶ点にあります。RIDM は以下のようなステップで実施されます。このプロセスは、安全工学に限らず、UI設計や運用業務の変更、サ プライチェーンリスク等にも応用可能です。 ●課題の特定とスコープ設定 ●関連するリスク評価情報の収集 ●設計・運用案 （選択肢） の策定 ●選択肢ごとのリスク比較と評価 ●価値判断と合意形成に基づく意思決定 ●決定根拠の文書化とフィードバックの活用 10.2 リスク評価情報の可視化と説明責任 リスク情報に基づいて意思決定を行うにあたり、評価内容が誰にとっても理解できる形で表現されているか、 そしてその判断の根拠が将来にわたって追跡可能かどうかは極めて重要です。いかに定量的なリスク評価がな されていても、それが一部の専門家だけに理解されるような形では、意思決定の正当性を社会的に説明するこ とは困難です。リスク情報の 「可視化」 と 「","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":89,"page_to":90,"char_count":1267},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c92","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"れます。 ●評価時点での仮定・前提条件の記録 ●使用したデータ・手法・モデルの明記 ●判断における選択肢と理由づけの文書化 ●意思決定に関与した関係者と合意形成の過程 このようにして、意思決定の背後にある思考プロセスを外部化・文書化することで、後から検証可能な状態を 保ちます。これは、単に 「安全である」 と主張するのではなく、 「どのように安全と判断したか」 を透明にする ために大切な観点です。記録管理については、 「DS-680.2﻿ウェブコンテンツガイドライン」 ［16﻿公開情報の品 質確保］ 及び ［18﻿記録管理］ も援用できるものですから、参考してください。\n\npage 90 10. リスク情報を活用した意思決定 10.3 安全文化と学習サイクルへの統合 リスクに基づいた意思決定を一過性の対応で終わらせないためには、組織全体で安全に対する共通理解と継 続的な学習の仕組み＝ 「安全文化」 を醸成する必要があります。ここでいう安全文化とは、 「安全は現場任せで はなく、組織全体の価値判断として根づくべきものである」 という認識に立ち、日常的な意思決定にリスク評 価を組み込む態度","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":90,"page_to":91,"char_count":1186},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c93","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"善提案を共有しても非難されない」 組織的な土壌＝心理的安全性 （Psychological﻿ Safety） を確保することです。 心理的安全性とは、 「この場で自分の考えを発言しても拒絶されたり評価を下げられたりしない」 と信じられ る状態のことであり、効果的なチームの最重要要因として繰り返し示されています。この心理的安全の醸成を 図るには、組織・チーム内での関係性の質を高めなければなりません。ダニエル・キムが提唱した 「成功循環 モデル （Core﻿Theory﻿of﻿Success） 」 は、組織の成果を 「結果」 から変えようとするのではなく、 「関係の質」 から見 直すことが、持続的な成果につながると説くものです。 要素 安全文化における意味 関係の質 上下・部署間を問わず、誰もが安全に発言・共有できる関係性 （心理的安全性） 思考の質 「この行動の背景には何があるか？ 」という構造的・非懲罰的な視点で考える 態度 行動の質 使用エラーやインシデントをオー プンに報告・記録・改善提案する行動の実践 結果の質 リスクの早期発見、安全設計の改善、組織とし ての信頼性の向上\n\npa","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":91,"page_to":92,"char_count":1269},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c94","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"ぜそうしたのか？」 ではなく 「その時どう 見えたか？」 等） 。問いには、 クローズドな質問 （ 「はい/いいえ」 で答えられるもの） とオープンな質問 （具体的な列挙 や叙述が求められる質問） 、具体的な質問と抽象的な質問等をシーンに応じて使い分けると良いでしょう。 行動の質を変える制度 報告した人を責めず、 報告そのものを評価する仕組みの制度化。潜在的なリスクの 「見える化」 を推奨します。 なお、 行動の質を変えるには、 多様な立場の声を汲み取るフィードバック構造を作り、 各ステークホルダーがそ れぞれの認識・判断・行動に別々のプロトコルを持っていると十分に自覚することが重要なポイントです。横 断的な議論の場 （シナリオワークショップ等） を設けること等も有効でしょう。 結果の質を活かす循環 報告から得た教訓をUIや業務マニュアルに反映し、定期的に 「変更理由」 を周知する。社内WikiやLT （ライ トニングトーク） の実施等も有効です。 全体の振り返り 安全文化の維持・醸成のプロセスの循環が組織内でどのように行われたか、振り返りの機会を設けることも 大切です。心理的安全が損","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":92,"page_to":93,"char_count":1262},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c95","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"熟度等のスケール （尺度） を用いても良いでしょう。 10.4 合意形成 現代のシステムでは、複雑なルールと評価基準、技術仕様、ガイドラインが錯綜し、設計・開発・運用に関 わる多様なステークホルダーが共通理解を持つこと自体が難しくなっています。さらに 「機能改修単位で発注 が行われ、実装する受託事業者が異なる」 「複数のプロジェクトにまたがって設計・運用される」 情報システム も多くなっています。このため、横断的かつ整合性のある監査基準、言い換えれば組織内外での合意形成のプ ロセスの設計が求められています。 情報システムの品質評価の透明性や公平性が欠けると、 現場では 「規制への一時対応」 に終始してしまい、 本 質的なユーザビリティや安全性が置き去りになるリスクがあります。というのも、例えば成果物の品質確認を 行う人による対応や判断の差がある、あるいは評価基準が透明性を欠くものになっている場合、対応コストが 見通せず大きな負担になってしまいます （プロジェクトが 「炎上」 しているときは特にそうです） 。対応を迫られる事 業者側も規制への目先の対応を優先してしまい、真にユーザビリティ","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":93,"page_to":94,"char_count":1261},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c96","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"共通の目標を共有できている状態をすぐに作れることは、情報システムの品質を継続的に向 上させるための土台になり、開発の失敗やインシデントのリスク低減につながります。 予見性 評価対象者 （事業者・開発者） が、必要な資源や対応策を事前に把握可能であるか。監査主体によって評価に 大きな違いがあると規制への目先の対応が横行するようになり、本来は中長期的に取り組むべき課題に取り組 めなくなってしまいます。開発の目標設定や設計の基準を定め、適切な開発プロセスを整備できるよう、品質 の基準を明確化することは、開発プロセスや工数の見通しを事業者や調達担当者が明確にする材料になります。 適時性 問題のある箇所を早期に特定し、修正できるプロセスが整備されているか。問題が発覚しても、修正するの に来年度まで待たなければならない状態では、情報システムを信頼して利用することができません。課題は発 見されるだけではなく、それが必要なタイミングで是正される必要があります。 公平性 「現実の利用状況における実際のパフォーマンス」 に焦点をあてているか。監査がチェックリスト偏重になる と規制が複雑かつ膨大になったり、","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":94,"page_to":95,"char_count":1292},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c97","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"非懲罰的かつ構造的な監査の文化を醸成する うえでも有用です。 10.4.1 安全に関する合意形成のためにやるべきこと 国民生活や企業活動に大きな影響を与えうる多くの行政サービスには複数の行政機関や業界団体、企業、専 門家、メディア等が関与しており、ステークホルダーの関係性も複雑です。これまで繰り返し述べてきたよう に、 「法令に従って設計されたから安心」 といった考え方はすでに限界を迎えています。むしろ、リスクが潜在 することを前提に、それらがどのように検出・制御・再設計されているかを、社会に対して説明し、共に評価 する枠組みが求められています。 このため、専門知識を持たない行政の担当者や、様々なステークホルダーが容易に取り扱える評価モデルを 共通言語として持ち、プロジェクト全体がチェックされるプロセスが正常に機能することで、社会的信頼が醸 成されるよう努めることが重要になってきます。 ●システムにどのようなハザードが潜在しうるかが構造的に可視化されていること ●想定される使用エラーや設計バイアスについて具体的に説明可能であること ●監査者・事業者・利用者のあいだで、評価基準とプロセス","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":95,"page_to":95,"char_count":1266},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c98","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"化 使用エラーや不確実性による影響 （損失） の可能性と、それに対する対策コストのバランスを確認・文書化し、 組織的に合意すること。このプロセスには、ヒヤリハットの蓄積やSTPAによる潜在的リスクの構造的把握が 含まれる。幅広い関係者からリスクに関する視点が提供され、 フレーミングの罠 （問題の枠組みフレームの設定の 仕方によって、判断や認識が偏ってしまう認知バイアス） に陥らないようにすること。\n\npage 95 10. リスク情報を活用した意思決定 パフォーマンスベースの評価 実使用状況に即した検証 （例：シナリオベース評価、クリック数、エラー率、達成時間） 。評価者間のばらつきを 最小化するためのプロトコル(手続き・手順)が整備され、計測できるようになっていること。検証者間での教 育・研修が行われ、定期的に指標や、環境の変化等を反映した活動が行われているか確認できること。システ ムのパフォーマンスに関する評価は、 「設計文書」 だけでなく、 「ユーザビリティテストの記録」 「インシデント ログ」 「UIプロトタイプ」 「A/Bテストの記録」 「コールセンターへの問合せ」 等の現物","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":95,"page_to":96,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c99","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"はできないことが出てきます。例えば以下のような問題です。 ●安全の基準を定義するのに、十分な情報がまだP J内にない ●リスク・ハザードの定義に、他のプロジェクトのリスク情報が必要である ●ある取組の優先順位が、プロジェクト単体で決められない （組織的決断が必要である） ●誰に、どのようなコミュニケーションをどのタイミングで取るべきかが定まらない ●複数のステークホルダーが安全確保において重要な役割を担っている こうした課題を乗り越えていくには、普段からプロセスの標準化や、十分に予見可能な対策の実施に向けた 情報・基準の管理が欠かせませんし、適切な記録管理が行われること、適切にスケジューリングされること等 も大切です。開発者・P JMO・利用者代表等多様なステークホルダーと随時コンテキストの共有が行われ、合 意形成のプロセスが段階的に踏まれていかないと、全員にとって負担が大きすぎることになるからです。 しかし、異なる階層・組織間でのコミュニケーションコストを低減させ、潜在リスクを早期に洗い出すため には ［10.3.1 安全文化のための制度的支援］ で示したような組織的な基盤が欠かせま","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":96,"page_to":97,"char_count":1259},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c100","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"が対話を通じて学び続けることが、事故の未然防止 だけでなく、信頼されるサービス設計に不可欠であることを強調しています。 従来、ユーザビリティと安全性やセキュリティ、プライバシーといった観点はしばしば別々に扱われがちで したが、本書を通じて、各要素は本質的に密接に結びついており、 「人が安心して使えること」 こそが、 「シス テム全体の信頼性を支える基盤」 であることをご理解いただけたかと思います。 現代の情報システムは、かつてないほど多くの人と技術が複雑に絡み合い、設計や運用の判断が難しくなっ ています。その中で私たちは、 「エラーが起きないように人を管理する」 という旧来型の発想から、 「エラーが 起きることを前提に、どう安全に制御するか」 というレジリエンス （回復力） を軸とした発想へと転換する必要 に迫られています。本ガイドブックが、そうした思考と実践の橋渡しを担い、より多くの機器・サービスが人 にとって使いやすく、安全で、信頼できるものとなる一助になれば幸いです。\n\npage 97 11. 付録 11 付録 11.1 リンク集 ユーザビリティに関するツールや情報は、多くがイン","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":97,"page_to":99,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c101","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"理推進機構\n\npage 98 11. 付録 11.2 参考文献 1. The National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research. 1979. The Belmont Report: Ethical Principles and Guidelines for the Protection of Human Subjects of Research. U.S. Department of Health and Human Services. https://www.hhs.gov/ohrp/ regulations-and-policy/belmont-report/index.html 2. Amartya Sen. 1979. Equality of what? In The Tanner Lecture on Human Values, delivered at Stanford University (May 22, 1979). Stanfo","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":98,"page_to":99,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c102","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"er） https://ddc.dk/vaerktoejer/toolkit-the-digital- ethics-compass/ 7. 平沢 尚毅・福住 伸一 編／著 （2023） ． 『顧客経験を指向するインタラクション――自律システムの社会 実装に向けた人間工学国際標準』 ．日本経済評論社． 8. 福住 伸一・平沢 尚毅 （2024） ． 『詳説 ユーザビリティのための産業共通様式 CIF: Common Industry Format for usability』 ．近代科学社Digital． 9. Jakob Nielsen and Thomas K. Landauer. 1993. A mathematical model of the finding of usability problems. In Proceedings of the INTERACT '93 and CHI '93 Conference on Human Factors in Computing Systems (CHI '93). Association for Computing Machi","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":99,"page_to":99,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c103","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"mory processes in perception and cognition. In The Structure of Human Memory, C.N. Cofer (Ed.). W.H. Freeman, 114–132. 13. David E. Rumelhart and Andrew Ortony. 1977. The representation of knowledge in memory. In Schooling and the Acquisition of Knowledge, R.C. Anderson, R.J. Spiro, and W.E. Montague (Eds.). Lawrence Erlbaum Associates, 99–135. 14. Donald A. Norman. 1981. Categorization of action slips. Psychological Review 88, 1 (January 1981), 1–15. 15. James Reason. 1987. Generic error-modell","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":99,"page_to":99,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c104","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"le. In Resilience Engineering: Concepts and Precepts, E. Hollnagel, D.D. Woods, and N. Leveson (Eds.). Ashgate Publishing, 9–17. 20. Nancy G. Leveson. 2012. Engineering a Safer World: Systems Thinking Applied to Safety. MIT Press. 兼本茂・福島祐子監訳 （2022） ． 『システム理論による安全工学——想定外に気づくための思考法 STAMP』 ．共立出版．\n\npage 99 索引 あ行 アクセシビリティ ⸺ファー ストの原則… ……………………………………… 21 ⸺ファー ストの原則の説明… ……………………………… 22 ⸺の説明… ………………………………………………… 22 JIS X 8341シリー ズと⸺… ………………………………… 23 ⸺の環境整備・合理的配慮とし ての代替手段…………… … ……………… … …………………… … ……………","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":99,"page_to":100,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c105","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"… ………………………………………………… … ………………………………………………… 71 活性化消失エラー ⸺の説明 56 完了後エラー ⸺の説明 57 記述類似性エラー ⸺の説明 56 コミッションエラー ⸺の説明 54 さ行 自己記述性 ⸺の説明… ………………………………………………… … ………………………………………………… … ……………………………………… ……………………………………………… 26 システムイメージ ⸺の説明 17 人間中心の原則と⸺ 36 使用エラーと⸺ 53 シングルループ学習 ⸺の説明… ………………………………………………… … …………………………………………… … ……………………………………… … …………………………………………… … ……………………………………………… … …………………………………………… … ……………………………………………… … …………………… … ………………… ………………… 90 使用エラー ⸺の概要説明 12 ⸺への耐性の確保 30 ⸺の詳細説明 52 代表的な⸺ 54 意図しない⸺ 54 意図的","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":100,"page_to":100,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c106","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"……………………………… … …………… … ………………………………………………… …………………… … ………………………………………………… … ………………………… … ………………………………………………… 56 スリップ ⸺の説明 55 フォールトツリー分析 （FTA） を用いた⸺の評価 67 人間信頼性アセスメントを用いた⸺の評価 72 成功循環モデル ⸺の説明 90 た行 タイミングエラー ⸺の説明 54 対話の原則 ユーザビリティデザインの原則と⸺の関係 21 ⸺の説明 24 ダークパターン ディセプティブパター ンを見よ ダブルループ学習 ⸺の説明 90 多様性 多様性 リプレゼンテーションを見よ タンパープルーフ ⸺の説明 65\n\npage 100 索引 ディセプティブパターン ⸺とデザイン倫理… ……………………………………… … ………………………………………………… … ………………………………………………… … ………………………………………………… … ………………………………………………… 19 ⸺の説明 20 デザインモデル ⸺の説明 17 データ駆","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":100,"page_to":101,"char_count":1200},{"chunk_id":"85d49d8312776e72b4b77c63d51606fc_c107","doc_id":"85d49d8312776e72b4b77c63d51606fc","text":"… ………………………………… 16 ⸺の説明 18 使用エラーと⸺の関係 30 情報提示の原則と⸺の関係 32 エラーチェー ン （事象連鎖） と⸺の関係 57 インシデント発生時の原因調査と⸺の関係 58 ハザード 使用エラーと⸺の関係 52 エラーチェーンにおける⸺の説明 57 ⸺の説明 63 STPAを用いた⸺の定義 76 STPAで特に注意すべき⸺………………………………… … ……………………………………… … ………………………………………… … …………………………………… … ……………………………………………… 77 ⸺の原因要因 （HSF） 81 ⸺シナリオ （HS） 82 ⸺シナリオ （HS） の例 82 ⸺の可視化 87 ヒューリスティック評価 ユーザビリティテスト （観察型） と⸺を組み合わせる… …… 43 ⸺の説明… ………………………………………………… … ……………………… ………………………… … ………………………………………………… …………………………………… …… … ………………………………………………… ………………………… …………","meeting":"デジタル社会推進標準ガイドライン","agency":"デジタル庁","title":"DS-671.1 ユーザビリティ導入ガイドブック（PDF／10,594KB）","date":"2023-07-04","url":"https://www.digital.go.jp/assets/contents/node/basic_page/field_ref_resources/e2a06143-ed29-4f1d-9c31-0f06fca67afc/91365885/20251016_introduction_to_usability.pdf","page_from":101,"page_to":101,"char_count":1200}],"avg_length":1204.384705882353,"k1":1.5,"b":0.75}