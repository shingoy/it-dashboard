name: Government IT Meeting Crawler

on:
  schedule:
    - cron: '0 21 * * *'
  workflow_dispatch:

jobs:
  crawl-and-build:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run crawler
        run: python scripts/crawl.py
        continue-on-error: true
      
      - name: Run extraction
        run: python scripts/extract.py
        continue-on-error: true
      
      - name: Build index
        run: python scripts/build_index.py
        continue-on-error: true
      
      - name: Commit changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add public/ data/docs_cache.json || true
          
          if ! git diff --quiet || ! git diff --staged --quiet; then
            git commit -m "Auto-update search index [skip ci]"
            
            # Pull with rebase to avoid conflicts
            git pull --rebase origin main || true
            
            # Push changes
            git push origin main || echo "Push failed, will retry next time"
          else
            echo "No changes to commit"
          fi
        continue-on-error: true
