name: Government IT Meeting Crawler

on:
  schedule:
    - cron: '0 18 * * *'  # 毎日 UTC 18:00 (JST 03:00) に実行
  workflow_dispatch:       # 手動実行も可能

jobs:
  crawl-and-build:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run crawler
        run: python scripts/crawl.py
        continue-on-error: true
      
      - name: Run extraction
        timeout-minutes: 10
        run: python scripts/extract.py
        continue-on-error: true
      
      - name: Build index
        run: python scripts/build_index.py
        continue-on-error: true
      
      - name: Check generated files
        id: check_files
        run: |
          if [ -d "public/index-shards" ] && [ "$(ls -A public/index-shards)" ]; then
            echo "files_exist=true" >> $GITHUB_OUTPUT
            echo "✅ Files generated successfully"
            ls -la public/index-shards/
          else
            echo "files_exist=false" >> $GITHUB_OUTPUT
            echo "⚠️ No files generated, skipping commit"
          fi
      
      - name: Commit and push changes
        if: steps.check_files.outputs.files_exist == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add public/ data/ || true
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Auto-update search index [skip ci]"
            git pull --rebase origin main || true
            git push origin main
            echo "✅ Changes pushed successfully"
          fi